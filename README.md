<h1 align="center">
  Llama2-Chinese
</h1>
<p align="center" width="100%">
  <img src="assets/llama.png" alt="Llama" style="width: 20%; display: block; margin: auto;"></a>
</p>
<p align="center">
  <font face="é»‘ä½“" color=orange size="6"> æœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ </font>
</p>
<p align="center">
  <a href="https://llama.family">åœ¨çº¿ä½“éªŒï¼šllama.family</a>
</p>
<p align="center">
  <a href="https://huggingface.co/FlagAlpha/Atom-7B">åŸºäºLlama2çš„å¼€æºä¸­æ–‡é¢„è®­ç»ƒå¤§æ¨¡å‹Atom-7B</a>
</p>

</br></br>


## ğŸ—‚ï¸ å†…å®¹å¯¼å¼•
- [ğŸ¼ å›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ï¼](#-å›½å†…llama2æœ€æ–°ä¸‹è½½åœ°å€)
- [ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlamaä¸­æ–‡ç¤¾åŒº](#-ç¤¾åŒºä»‹ç»llamaä¸­æ–‡ç¤¾åŒº)
- [ğŸ“¢ ç¤¾åŒºå…¬å‘Š](#-ç¤¾åŒºå…¬å‘Š)
- [ğŸ”µ Atomæ¨¡å‹](#-atomæ¨¡å‹)
  - [å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ](#å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ)
  - [æ›´é«˜æ•ˆçš„ä¸­æ–‡è¯è¡¨](#æ›´é«˜æ•ˆçš„ä¸­æ–‡è¯è¡¨)
  - [è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ‰©å±•](#è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ‰©å±•)
- [ğŸ“ æ•°æ®æ¥æº](#-æ•°æ®æ¥æº)
- [â¬ æ¨¡å‹éƒ¨ç½²](#-æ¨¡å‹éƒ¨ç½²)
  - [æ¨¡å‹ä¸‹è½½](#æ¨¡å‹ä¸‹è½½)
    - [Metaå®˜æ–¹Llama2æ¨¡å‹](#metaå®˜æ–¹llama2æ¨¡å‹)
    - [åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹](#åŸºäºllama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹)
    - [åŸºäºLlama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom](#åŸºäºllama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹atom)
  - [æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹](#æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹)
  - [FastAPIæ¥å£æ­å»º](#fastapiæ¥å£æ­å»º)
  - [Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°](#gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°)
  - [Dockeréƒ¨ç½²é—®ç­”æ¥å£](#dockeréƒ¨ç½²é—®ç­”æ¥å£)
- [ğŸ’¡ æ¨¡å‹å¾®è°ƒ](#-æ¨¡å‹å¾®è°ƒ)
  - [å¾®è°ƒè¿‡ç¨‹](#å¾®è°ƒè¿‡ç¨‹)
    - [Step1: ç¯å¢ƒå‡†å¤‡](#step1-ç¯å¢ƒå‡†å¤‡)
    - [Step2: æ•°æ®å‡†å¤‡](#step2-æ•°æ®å‡†å¤‡)
    - [Step3: å¾®è°ƒè„šæœ¬](#step3-å¾®è°ƒè„šæœ¬)
  - [åŠ è½½å¾®è°ƒæ¨¡å‹](#åŠ è½½å¾®è°ƒæ¨¡å‹)
- [ğŸ„ æ¨¡å‹é‡åŒ–](#-æ¨¡å‹é‡åŒ–)
- [ğŸš€ æ¨ç†åŠ é€Ÿ](#-æ¨ç†åŠ é€Ÿ)
  - [lmdeploy](#lmdeploy)
  - [FasterTransformer](#fastertransformer)
  - [vLLM](#vllm)
- [ğŸ¥‡ æ¨¡å‹è¯„æµ‹](#-æ¨¡å‹è¯„æµ‹)
- [ğŸ’ª å¤–å»¶èƒ½åŠ›](#-å¤–å»¶èƒ½åŠ›)
  - [LangChain](#langchain)
- [ğŸ ä»£ç æ¨¡å‹](#-ä»£ç æ¨¡å‹)
- [ğŸ“– å­¦ä¹ èµ„æ–™](#-å­¦ä¹ èµ„æ–™)
  - [Metaå®˜æ–¹å¯¹äºLlama2çš„ä»‹ç»](#metaå®˜æ–¹å¯¹äºllama2çš„ä»‹ç»)
  - [Llamaç›¸å…³è®ºæ–‡](#llamaç›¸å…³è®ºæ–‡)
  - [Llama2çš„è¯„æµ‹ç»“æœ](#llama2çš„è¯„æµ‹ç»“æœ)
- [ğŸ‰ è‡´è°¢](#-è‡´è°¢)
- [ğŸ¤” é—®é¢˜åé¦ˆ](#-é—®é¢˜åé¦ˆ)



## ğŸ¼ å›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ï¼

æœ¬ä»“åº“ä¸­çš„ä»£ç ç¤ºä¾‹ä¸»è¦æ˜¯åŸºäºHugging Faceç‰ˆæœ¬å‚æ•°è¿›è¡Œè°ƒç”¨ï¼Œæˆ‘ä»¬æä¾›äº†è„šæœ¬å°†Metaå®˜ç½‘å‘å¸ƒçš„æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºHugging Faceæ”¯æŒçš„æ ¼å¼ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡transformersåº“è¿›è¡ŒåŠ è½½ï¼š[å‚æ•°æ ¼å¼è½¬åŒ–](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/scripts/convert2hf/READMD.md)


<details>

- Llama2-7Bå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf

- Llama2-7B-Chatå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra

- Llama2-13Bå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb

- Llama2-13B-Chatå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw

- Llama2-7B Hugging Faceç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep

- Llama2-7B-Chat Hugging Faceç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir

- Llama2-13B Hugging Faceç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf
  
- Llama2-13B-Chat Hugging Faceç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg

- Llama2-70B-Chat Hugging Faceç‰ˆæœ¬ï¼šhttps://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#

- CodeLlama-7bå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.baidu.com/s/1cIPzdNywWLvQI7_2QanOEQ?pwd=zfwi 

- CodeLlama-7b-Pythonå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.baidu.com/s/1liY8klGoDagYbpw-g-oFag?pwd=i952

- CodeLlama-7b-Instructå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.baidu.com/s/108o9_DT2E_vfSGtOnDCQVw?pwd=zkt9

- CodeLlama-13bå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.baidu.com/s/1lLaeHv0XEBv0iiZzI1dpnw?pwd=qn99

- CodeLlama-13b-Pythonå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.baidu.com/s/1OLVfvZS_oqL3oqMKwsI87w?pwd=a78k

- CodeLlama-13b-Instructå®˜ç½‘ç‰ˆæœ¬ï¼šhttps://pan.baidu.com/s/1HyxJl4w8wElgkZRh2ATrXQ?pwd=seg6

</details>

## ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlamaä¸­æ–‡ç¤¾åŒº

æ¬¢è¿æ¥åˆ°Llamaä¸­æ–‡ç¤¾åŒºï¼æˆ‘ä»¬æ˜¯ä¸€ä¸ªä¸“æ³¨äºLlamaæ¨¡å‹åœ¨ä¸­æ–‡æ–¹é¢çš„ä¼˜åŒ–å’Œä¸Šå±‚å»ºè®¾çš„é«˜çº§æŠ€æœ¯ç¤¾åŒºã€‚
**\*åŸºäºå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®ï¼Œä»é¢„è®­ç»ƒå¼€å§‹å¯¹Llama2æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§\***ã€‚
æˆ‘ä»¬çƒ­å¿±æ¬¢è¿å¯¹å¤§æ¨¡å‹LLMå……æ»¡çƒ­æƒ…çš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥æˆ‘ä»¬çš„è¡Œåˆ—ã€‚

<details>

### ä¸ºä»€ä¹ˆé€‰æ‹©Llama2ä¸­æ–‡ç¤¾åŒºï¼Ÿ
ğŸš€ **é«˜çº§å·¥ç¨‹å¸ˆå›¢é˜Ÿæ”¯æŒ**ï¼šç¤¾åŒºæœ‰ä¸€æ‰¹ä¸“æ³¨ä¸ºå¤§å®¶æœåŠ¡çš„NLPé«˜çº§å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬æœ‰ç€å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒå’Œä¸°å¯Œçš„ç»éªŒï¼Œä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŒ‡å¯¼å’Œå¸®åŠ©ã€‚

ğŸ¯ **ä¸­æ–‡ä¼˜åŒ–**ï¼šæˆ‘ä»¬è‡´åŠ›äºåœ¨Llama2æ¨¡å‹çš„ä¸­æ–‡å¤„ç†æ–¹é¢è¿›è¡Œä¼˜åŒ–ï¼Œæ¢ç´¢é€‚ç”¨äºä¸­æ–‡çš„æœ€ä½³å®è·µï¼Œä»¥æå‡å…¶æ€§èƒ½å’Œé€‚åº”æ€§ã€‚

ğŸ’¡ **åˆ›æ–°äº¤æµ**ï¼šæˆ‘ä»¬æ‹¥æœ‰ä¸€æ”¯å¯Œæœ‰åˆ›é€ åŠ›å’Œç»éªŒçš„ç¤¾åŒºæˆå‘˜å›¢é˜Ÿï¼Œå®šæœŸç»„ç»‡çº¿ä¸Šæ´»åŠ¨ã€æŠ€æœ¯ç ”è®¨å’Œç»éªŒåˆ†äº«ï¼Œä¿ƒè¿›æˆå‘˜é—´çš„åˆ›æ–°äº¤æµã€‚

ğŸŒ **å…¨çƒè”ç»“**ï¼šæˆ‘ä»¬æ¬¢è¿æ¥è‡ªä¸–ç•Œå„åœ°çš„å¼€å‘è€…åŠ å…¥ç¤¾åŒºï¼Œæ„å»ºä¸€ä¸ªå¼€æ”¾ã€å¤šå…ƒåŒ–çš„å­¦ä¹ å’Œäº¤æµå¹³å°ã€‚

ğŸ¤ **å¼€æ”¾å…±äº«**ï¼šæˆ‘ä»¬é¼“åŠ±ç¤¾åŒºæˆå‘˜å¼€æºåˆ†äº«ä»£ç å’Œæ¨¡å‹ï¼Œæ¨åŠ¨åˆä½œå…±èµ¢ï¼Œå…±åŒä¿ƒè¿›ä¸­æ–‡NLPæŠ€æœ¯çš„å‘å±•ã€‚

### ç¤¾åŒºæ´»åŠ¨
ğŸ—“ï¸ **çº¿ä¸Šè®²åº§**ï¼šé‚€è¯·è¡Œä¸šå†…ä¸“å®¶è¿›è¡Œçº¿ä¸Šè®²åº§ï¼Œåˆ†äº«Llama2åœ¨ä¸­æ–‡NLPé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯å’Œåº”ç”¨ï¼Œæ¢è®¨å‰æ²¿ç ”ç©¶æˆæœã€‚

ğŸ’» **é¡¹ç›®å±•ç¤º**ï¼šæˆå‘˜å¯å±•ç¤ºè‡ªå·±åœ¨Llama2ä¸­æ–‡ä¼˜åŒ–æ–¹é¢çš„é¡¹ç›®æˆæœï¼Œè·å¾—åé¦ˆå’Œå»ºè®®ï¼Œä¿ƒè¿›é¡¹ç›®åä½œã€‚

ğŸ“š **å­¦ä¹ èµ„æº**ï¼šç¤¾åŒºç»´æŠ¤ä¸°å¯Œçš„å­¦ä¹ èµ„æ–™åº“ï¼ŒåŒ…æ‹¬æ•™ç¨‹ã€æ–‡æ¡£å’Œè®ºæ–‡è§£è¯»ï¼Œä¸ºæˆå‘˜æä¾›å…¨é¢çš„å­¦ä¹ æ”¯æŒã€‚

ğŸ“ **è®ºæ–‡è§£è¯»**ï¼šç¤¾åŒºæˆå‘˜å…±åŒè§£è¯»ä¸Llama2ç›¸å…³çš„æœ€æ–°ç ”ç©¶è®ºæ–‡ï¼Œæ·±å…¥ç†è§£å‰æ²¿ç®—æ³•å’Œæ–¹æ³•ã€‚

ğŸ‰ **ä¸»é¢˜æ´»åŠ¨**ï¼šå®šæœŸä¸¾åŠå„ç±»ä¸»é¢˜æ´»åŠ¨ï¼ŒåŒ…æ‹¬æŒ‘æˆ˜èµ›ã€é»‘å®¢é©¬æ‹‰æ¾å’ŒæŠ€æœ¯æ²™é¾™ï¼Œè®©ç¤¾åŒºæˆå‘˜åœ¨è½»æ¾æ„‰å¿«çš„æ°›å›´ä¸­äº¤æµå’Œå­¦ä¹ ã€‚

ğŸŒŸ **å¥–åŠ±è®¡åˆ’**ï¼šæˆ‘ä»¬è®¾ç«‹å¥–åŠ±è®¡åˆ’ï¼Œå¯¹ç¤¾åŒºä¸­ç§¯æå‚ä¸ã€è´¡çŒ®ä¼˜ç§€çš„æˆå‘˜ç»™äºˆè£èª‰å’Œå¥–åŠ±ï¼Œæ¿€åŠ±æ›´å¤šä¼˜ç§€äººæ‰çš„åŠ å…¥ã€‚

ğŸ“ˆ **æŠ€æœ¯å’¨è¯¢**ï¼šæˆ‘ä»¬æä¾›æŠ€æœ¯å’¨è¯¢æœåŠ¡ï¼Œè§£ç­”æ‚¨åœ¨Llama2å¼€å‘å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ï¼ŒåŠ©æ‚¨å¿«é€Ÿæ”»å…‹éš¾å…³ã€‚

ğŸš€ **é¡¹ç›®åˆä½œ**ï¼šé¼“åŠ±æˆå‘˜é—´çš„é¡¹ç›®åˆä½œï¼Œå…±åŒæ¢ç´¢Llama2åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ï¼Œæ‰“é€ åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚


### ç«‹å³åŠ å…¥æˆ‘ä»¬ï¼
ğŸ“š **æ„¿æ™¯**ï¼šæ— è®ºæ‚¨æ˜¯å¯¹Llama2å·²æœ‰ç ”ç©¶å’Œåº”ç”¨ç»éªŒçš„ä¸“ä¸šå¼€å‘è€…ï¼Œè¿˜æ˜¯å¯¹Llama2ä¸­æ–‡ä¼˜åŒ–æ„Ÿå…´è¶£å¹¶å¸Œæœ›æ·±å…¥æ¢ç´¢çš„æ–°æ‰‹ï¼Œæˆ‘ä»¬éƒ½çƒ­åˆ‡æœŸå¾…æ‚¨çš„åŠ å…¥ã€‚åœ¨Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ‚¨å°†æœ‰æœºä¼šä¸è¡Œä¸šå†…é¡¶å°–äººæ‰å…±åŒäº¤æµï¼Œæºæ‰‹æ¨åŠ¨ä¸­æ–‡NLPæŠ€æœ¯çš„è¿›æ­¥ï¼Œå¼€åˆ›æ›´åŠ ç¾å¥½çš„æŠ€æœ¯æœªæ¥ï¼

ğŸ”— **æ¸©é¦¨æç¤º**ï¼šæœ¬ç¤¾åŒºä¸ºä¸“ä¸šæŠ€æœ¯äº¤æµå¹³å°ï¼Œæˆ‘ä»¬çƒ­åˆ‡æœŸæœ›å¿—åŒé“åˆçš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥ã€‚è¯·éµå®ˆç¤¾åŒºå‡†åˆ™ï¼Œå…±åŒç»´æŠ¤ç§¯æå‘ä¸Šçš„å­¦ä¹ æ°›å›´ï¼Œä»»ä½•ä¸Llama2æ— å…³çš„å†…å®¹å’Œå¹¿å‘Šå°†è¢«æ¸…ç†ã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£å’Œæ”¯æŒï¼

</details>

## ğŸ“¢ ç¤¾åŒºå…¬å‘Š

ã€æœ€æ–°ã€‘2023å¹´8æœˆ28æ—¥ï¼šå‘å¸ƒåŸºäºLlama2è¿›è¡Œä¸­æ–‡é¢„è®­ç»ƒçš„å¼€æºå¤§æ¨¡å‹[Atom-7B](https://huggingface.co/FlagAlpha/Atom-7B)ï¼Œå¹¶å°†æŒç»­æ›´æ–°ï¼Œè¯¦æƒ…å‚è€ƒ[ç¤¾åŒºå…¬ä¼—å·æ–‡ç« ](https://mp.weixin.qq.com/s/Bdx0JTVh1kgPn5ydYxIkEw)ï¼

<details>

- 2023å¹´8æœˆ26æ—¥ï¼šæä¾›[FastAPI](#fastapiæ¥å£æ­å»º)æ¥å£æ­å»ºè„šæœ¬ï¼

- 2023å¹´8æœˆ26æ—¥ï¼šæä¾›å°†MetaåŸå§‹æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºå…¼å®¹Hugging Faceçš„[æ ¼å¼è½¬åŒ–è„šæœ¬](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/scripts/convert2hf/READMD.md)ï¼

- 2023å¹´8æœˆ26æ—¥ï¼šæ–°å¢[Code Llama](#-ä»£ç æ¨¡å‹)æ¨¡å‹ï¼

- 2023å¹´8æœˆ15æ—¥ï¼šæ–°å¢[PEFTåŠ è½½å¾®è°ƒæ¨¡å‹å‚æ•°](#åŠ è½½å¾®è°ƒæ¨¡å‹)çš„ä»£ç ç¤ºä¾‹ï¼

- 2023å¹´8æœˆ14æ—¥ï¼š[å¤§æ¨¡å‹æ•°æ®å…±äº«è®­ç»ƒå¹³å°](https://llama.family)ä¸Šçº¿ï¼Œæ²¡æœ‰ç®—åŠ›ä¹Ÿèƒ½å‚ä¸å¤§æ¨¡å‹è®­ç»ƒï¼Œç¤¾åŒºæ¯ä½æˆå‘˜è´¡çŒ®çš„æ•°æ®éƒ½å°†å†³å®šæ¨¡å‹èƒ½åŠ›çš„æœªæ¥èµ°å‘ï¼

- 2023å¹´8æœˆ3æ—¥ï¼šæ–°å¢FasterTransformerå’ŒvLLMçš„GPU[æ¨ç†åŠ é€Ÿ](#-æ¨ç†åŠ é€Ÿ)æ”¯æŒï¼

- 2023å¹´7æœˆ31æ—¥ï¼šã€é‡ç£…ã€‘å›½å†…é¦–ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„Llama2ä¸­æ–‡å¤§æ¨¡å‹å‘å¸ƒï¼è¯¦æƒ…å‚è§[ç¤¾åŒºå…¬ä¼—å·æ–‡ç« ](https://mp.weixin.qq.com/s/lExUU7z_MvgJ7tzQPF8tUQ)

- 2023å¹´7æœˆ28æ—¥ï¼šé€šè¿‡[Dockeréƒ¨ç½²](#dockeréƒ¨ç½²é—®ç­”æ¥å£)é—®ç­”æ¥å£ï¼

- 2023å¹´7æœˆ27æ—¥ï¼šæ–°å¢[LangChain](#langchain)æ”¯æŒï¼

- 2023å¹´7æœˆ26æ—¥ï¼šæ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°çš„[4bité‡åŒ–å‹ç¼©ç‰ˆæœ¬](#-æ¨¡å‹é‡åŒ–)ï¼

- 2023å¹´7æœˆ25æ—¥ï¼šç¤¾åŒºå¾®ä¿¡å…¬ä¼—å·â€œLlamaä¸­æ–‡ç¤¾åŒºâ€æ¬¢è¿å¤§å®¶å…³æ³¨ï¼Œè·å–æœ€æ–°åˆ†äº«å’ŒåŠ¨æ€ï¼

- 2023å¹´7æœˆ24æ—¥ï¼š[FlagAlpha](https://huggingface.co/FlagAlpha)æ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°ï¼

- 2023å¹´7æœˆ24æ—¥ï¼š[llama.family](https://llama.family/)æ–°å¢Llama2-70Båœ¨çº¿ä½“éªŒï¼

- 2023å¹´7æœˆ23æ—¥ï¼šLlama2ä¸­æ–‡å¾®è°ƒå‚æ•°å‘å¸ƒè‡³Hugging Faceä»“åº“[FlagAlpha](https://huggingface.co/FlagAlpha)ï¼

- 2023å¹´7æœˆ22æ—¥ï¼šLlama2åœ¨çº¿ä½“éªŒé“¾æ¥[llama.family](https://llama.family/)ä¸Šçº¿ï¼ŒåŒæ—¶åŒ…å«MetaåŸç‰ˆå’Œä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼

- 2023å¹´7æœˆ21æ—¥ï¼šè¯„æµ‹äº†MetaåŸå§‹ç‰ˆLlama2 Chatæ¨¡å‹çš„[ä¸­æ–‡é—®ç­”èƒ½åŠ›](#-æ¨¡å‹è¯„æµ‹)ï¼

- 2023å¹´7æœˆ21æ—¥ï¼šæ–°å¢Llama2æ¨¡å‹çš„Hugging Faceç‰ˆæœ¬å›½å†…ä¸‹è½½åœ°å€ï¼

- 2023å¹´7æœˆ20æ—¥ï¼šæ–°å¢[é£ä¹¦çŸ¥è¯†åº“æ–‡æ¡£](https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink)ï¼Œæ¬¢è¿å¤§å®¶ä¸€èµ·å…±å»ºï¼

- 2023å¹´7æœˆ20æ—¥ï¼šå›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼

- 2023å¹´7æœˆ19æ—¥ï¼šæ­£å¼å¯åŠ¨Llama2æ¨¡å‹çš„ä¸­æ–‡é¢„è®­ç»ƒï¼Œå…³æ³¨æˆ‘ä»¬è·å–å®æ—¶åŠ¨æ€ï¼

- 2023å¹´7æœˆ19æ—¥ï¼šLlama2å›½å†…ä¸‹è½½åœ°å€æ­£åœ¨å¯åŠ¨ï¼Œæ•¬è¯·æœŸå¾…ï¼

- 2023å¹´7æœˆ19æ—¥ï¼šå¼€å¯Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ï¼

</details>



## ğŸ”µ Atomæ¨¡å‹

**åŸå­å¤§æ¨¡å‹Atom**ç”±Llamaä¸­æ–‡ç¤¾åŒºå’ŒåŸå­å›å£°è”åˆæ‰“é€ ï¼Œåœ¨ä¸­æ–‡å¤§æ¨¡å‹è¯„æµ‹æ¦œå•C-Evalä¸­ä½å±…å‰åï¼ˆ8æœˆ21æ—¥è¯„æµ‹æäº¤æ—¶é—´ï¼‰ã€‚
<p align="center" width="100%">
<img src="./assets/ceval.jpg" alt="ceval" style="width: 100%; display: block; margin: auto;">
</p>

Atomç³»åˆ—æ¨¡å‹åŒ…å«Atom-7Bå’ŒAtom-13Bï¼ŒåŸºäºLlama2åšäº†ä¸­æ–‡èƒ½åŠ›çš„æŒç»­ä¼˜åŒ–ã€‚Atom-7Bç›®å‰å·²å®Œå…¨å¼€æºï¼Œæ”¯æŒå•†ç”¨ï¼Œå¯åœ¨[Hugging Face](https://huggingface.co/FlagAlpha/Atom-7B)ä»“åº“è·å–æ¨¡å‹ã€‚Atomå¤§æ¨¡å‹é’ˆå¯¹ä¸­æ–‡åšäº†ä»¥ä¸‹ä¼˜åŒ–ï¼š

### å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ

åŸå­å¤§æ¨¡å‹Atomåœ¨Llama2çš„åŸºç¡€ä¸Šï¼Œé‡‡ç”¨å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®è¿›è¡ŒæŒç»­é¢„è®­ç»ƒï¼ŒåŒ…å«ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ã€é‡‘èæ•°æ®ã€æ³•å¾‹æ•°æ®ã€åŒ»ç–—æ•°æ®ã€ä»£ç æ•°æ®ã€ä¸“ä¸šè®ºæ–‡æ•°æ®ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç«èµ›æ•°æ®é›†ç­‰ï¼Œè¯¦è§[ğŸ“ æ•°æ®æ¥æº](#-æ•°æ®æ¥æº)ã€‚

åŒæ—¶å¯¹åºå¤§çš„æ•°æ®è¿›è¡Œäº†è¿‡æ»¤ã€æ‰“åˆ†ã€å»é‡ï¼Œç­›é€‰å‡ºè¶…è¿‡1T tokençš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼ŒæŒç»­ä¸æ–­åŠ å…¥è®­ç»ƒè¿­ä»£ä¸­ã€‚

### æ›´é«˜æ•ˆçš„ä¸­æ–‡è¯è¡¨
ä¸ºäº†æé«˜ä¸­æ–‡æ–‡æœ¬å¤„ç†çš„æ•ˆç‡ï¼Œæˆ‘ä»¬é’ˆå¯¹Llama2æ¨¡å‹çš„è¯è¡¨è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åŸºäºæ•°ç™¾Gçš„ä¸­æ–‡æ–‡æœ¬ï¼Œåœ¨è¯¥æ¨¡å‹è¯è¡¨çš„åŸºç¡€ä¸Šæ‰©å±•è¯åº“è‡³65,000ä¸ªå•è¯ã€‚ç»è¿‡æµ‹è¯•ï¼Œæˆ‘ä»¬çš„æ”¹è¿›ä½¿å¾—ä¸­æ–‡ç¼–ç /è§£ç é€Ÿåº¦æé«˜äº†çº¦350ï¼…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ‰©å¤§äº†ä¸­æ–‡å­—ç¬¦é›†çš„è¦†ç›–èŒƒå›´ï¼ŒåŒ…æ‹¬æ‰€æœ‰emojiç¬¦å·ğŸ˜Šã€‚è¿™ä½¿å¾—ç”Ÿæˆå¸¦æœ‰è¡¨æƒ…ç¬¦å·çš„æ–‡ç« æ›´åŠ é«˜æ•ˆã€‚

### è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ‰©å±•
Atomå¤§æ¨¡å‹é»˜è®¤æ”¯æŒ4Kä¸Šä¸‹æ–‡ï¼Œåˆ©ç”¨ä½ç½®æ’å€¼PIå’ŒNeural Tangent Kernel ï¼ˆNTKï¼‰æ–¹æ³•ï¼Œç»è¿‡å¾®è°ƒå¯ä»¥å°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å¢åˆ°32Kã€‚



## ğŸ“ æ•°æ®æ¥æº

æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ•°æ®æ¥ä¼˜åŒ–Llama2çš„ä¸­æ–‡èƒ½åŠ›:

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| ç½‘ç»œæ•°æ®                                                   | äº’è”ç½‘ä¸Šå…¬å¼€çš„ç½‘ç»œæ•°æ®ï¼ŒæŒ‘é€‰å‡ºå»é‡åçš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼Œæ¶‰åŠåˆ°ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ç­‰é«˜è´¨é‡é•¿æ–‡æœ¬æ•°æ®ã€‚ |
| [Wikipedia](https://github.com/goldsmith/Wikipedia)        | ä¸­æ–‡Wikipediaçš„æ•°æ®                                          |
| [æ‚Ÿé“](https://github.com/BAAI-WuDao/Model)                | ä¸­æ–‡æ‚Ÿé“å¼€æºçš„200Gæ•°æ®                                       |
| [Clue](https://github.com/CLUEbenchmark/CLUEDatasetSearch) | Clueå¼€æ”¾çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—åçš„é«˜è´¨é‡ä¸­æ–‡é•¿æ–‡æœ¬æ•°æ®   |
| ç«èµ›æ•°æ®é›†                                                 | è¿‘å¹´æ¥ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å¤šä»»åŠ¡ç«èµ›æ•°æ®é›†ï¼Œçº¦150ä¸ª              |
| [MNBVC](https://github.com/esbatmop/MNBVC)                 | MNBVC ä¸­æ¸…æ´—å‡ºæ¥çš„éƒ¨åˆ†æ•°æ®é›†                                 |

**å¸Œæœ›å¤§å®¶å¦‚æœæœ‰è¾ƒé«˜è´¨é‡çš„æ•°æ®é›†èƒ½å¤Ÿæä¾›ç»™æˆ‘ä»¬ï¼Œä¸èƒœæ„Ÿæ¿€!ğŸ’•ğŸ’•**



## â¬ æ¨¡å‹éƒ¨ç½²

Metaåœ¨ğŸ¤—Hugging Faceä¸Šæä¾›äº†æ‰€æœ‰æ¨¡å‹çš„ä¸‹è½½é“¾æ¥ï¼šhttps://huggingface.co/meta-llama

Llamaä¸­æ–‡ç¤¾åŒºçš„ä¸­æ–‡æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼šhttps://huggingface.co/FlagAlpha

### æ¨¡å‹ä¸‹è½½

#### Metaå®˜æ–¹Llama2æ¨¡å‹

Llama2é¢„è®­ç»ƒæ¨¡å‹åŒ…å«7Bã€13Bå’Œ70Bä¸‰ä¸ªç‰ˆæœ¬ã€‚Llama2-Chatæ¨¡å‹åŸºäºé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†ç›‘ç£å¾®è°ƒï¼Œå…·å¤‡æ›´å¼ºçš„å¯¹è¯èƒ½åŠ›ã€‚

|  ç±»åˆ«  | æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
|  ----------  | ---------- | ------------------------- | --------------------- |
|  é¢„è®­ç»ƒ  | Llama2-7B  | meta-llama/Llama-2-7b-hf  | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-7b-hf)  |
|  é¢„è®­ç»ƒ  | Llama2-13B | meta-llama/Llama-2-13b-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-13b-hf) |
|  é¢„è®­ç»ƒ  | Llama2-70B | meta-llama/Llama-2-70b-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-70b-hf) |
|  Chat  | Llama2-7B-Chat  | meta-llama/Llama-2-7b-chat-hf  | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) |
|  Chat  | Llama2-13B-Chat | meta-llama/Llama-2-13b-chat-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf) |
|  Chat  | Llama2-70B-Chat | meta-llama/Llama-2-70b-chat-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf) |


#### åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹

æˆ‘ä»¬åŸºäºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†å¯¹Llama2-Chatæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿å¾—Llama2æ¨¡å‹æœ‰ç€æ›´å¼ºçš„ä¸­æ–‡å¯¹è¯èƒ½åŠ›ã€‚LoRAå‚æ•°ä»¥åŠä¸åŸºç¡€æ¨¡å‹åˆå¹¶çš„å‚æ•°å‡å·²ä¸Šä¼ è‡³[Hugging Face](https://huggingface.co/FlagAlpha)ï¼Œç›®å‰åŒ…å«7Bå’Œ13Bçš„æ¨¡å‹ã€‚

|  ç±»åˆ«  | æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | åŸºç¡€æ¨¡å‹ç‰ˆæœ¬ |    ä¸‹è½½åœ°å€                                                     |
|  ----------  | ---------- | ------------- |  ----------------- | ------------------- |
|  åˆå¹¶å‚æ•° | Llama2-Chinese-7b-Chat | FlagAlpha/Llama2-Chinese-7b-Chat  |    meta-llama/Llama-2-7b-chat-hf       |[æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat)  |
|  åˆå¹¶å‚æ•° | Llama2-Chinese-13b-Chat | FlagAlpha/Llama2-Chinese-13b-Chat|     meta-llama/Llama-2-13b-chat-hf     |[æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat) |
|  LoRAå‚æ•° | Llama2-Chinese-7b-Chat-LoRA  | FlagAlpha/Llama2-Chinese-7b-Chat-LoRA  |     meta-llama/Llama-2-7b-chat-hf      |[æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat-LoRA) |
|  LoRAå‚æ•° | Llama2-Chinese-13b-Chat-LoRA | FlagAlpha/Llama2-Chinese-13b-Chat-LoRA |     meta-llama/Llama-2-13b-chat-hf     |[æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA) |


#### åŸºäºLlama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom

ç¤¾åŒºæä¾›Atom-7Bæ¨¡å‹çš„å¼€æ”¾ä¸‹è½½ï¼Œæ¨¡å‹å‚æ•°ä¼šæŒç»­ä¸æ–­æ›´æ–°ï¼Œå…³äºæ¨¡å‹çš„è¿›å±•è¯¦è§ç¤¾åŒºå®˜ç½‘[llama.family](https://llama.family)ã€‚

| æ¨¡å‹åç§°        | ğŸ¤—æ¨¡å‹åŠ è½½åç§°                  | ä¸‹è½½åœ°å€                                                     |
| --------------- | ------------------------------ | ------------------------------------------------------------ |
| Atom-7B  | FlagAlpha/Atom-7B  | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Atom-7B) |


### æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained('FlagAlpha/Atom-7B',device_map='auto',torch_dtype=torch.float16,load_in_8bit=True)
model =model.eval()
tokenizer = AutoTokenizer.from_pretrained('FlagAlpha/Atom-7B',use_fast=False)
tokenizer.pad_token = tokenizer.eos_token
input_ids = tokenizer(['<s>Human: ä»‹ç»ä¸€ä¸‹ä¸­å›½\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids.to('cuda')        
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```

### FastAPIæ¥å£æ­å»º

ä¸ºäº†æ–¹ä¾¿é€šè¿‡APIæ–¹å¼è°ƒç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬æä¾›äº†è„šæœ¬ç”¨æ¥å¿«é€Ÿæ­å»º[FastAPI](https://github.com/tiangolo/fastapi)æ¥å£ï¼Œç›¸å…³æµ‹è¯•ä»£ç ä¸APIå‚æ•°è®¾ç½®è§[API è°ƒç”¨](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/scripts/api/READMD.md)ã€‚

### Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°

åŸºäºgradioæ­å»ºçš„é—®ç­”ç•Œé¢ï¼Œå®ç°äº†æµå¼çš„è¾“å‡ºï¼Œå°†ä¸‹é¢ä»£ç å¤åˆ¶åˆ°æ§åˆ¶å°è¿è¡Œï¼Œä»¥ä¸‹ä»£ç ä»¥Atom-7Bæ¨¡å‹ä¸ºä¾‹ï¼Œ<font color="#006600">ä¸åŒæ¨¡å‹åªéœ€ä¿®æ”¹ä¸€ä¸‹ä»£ç é‡Œçš„æ¨¡å‹åç§°å°±å¥½äº†ğŸ˜Š</font><br/>
```
python examples/chat_gradio.py --model_name_or_path FlagAlpha/Atom-7B
```

### Dockeréƒ¨ç½²é—®ç­”æ¥å£
è¯¦æƒ…å‚è§ï¼š[Dockeréƒ¨ç½²](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/docs/chat_gradio_guide.md)

ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡dockeré•œåƒï¼Œé€šè¿‡dockerå®¹å™¨å¯åŠ¨[chat_gradio.py](../examples/chat_gradio.py)
```bash
git clone https://github.com/FlagAlpha/Llama2-Chinese.git

cd Llama2-Chinese

docker build -f docker/Dockerfile -t flagalpha/llama2-chinese-7b:gradio .
```

ç¬¬äºŒæ­¥ï¼šé€šè¿‡docker-composeå¯åŠ¨chat_gradio
```bash
cd Llama2-Chinese/docker
doker-compose up -d --build
```


## ğŸ’¡ æ¨¡å‹å¾®è°ƒ

æœ¬ä»“åº“ä¸­æä¾›äº†åŸºäºLoRAçš„å¾®è°ƒä»£ç ï¼Œæœªæ¥æˆ‘ä»¬å°†ä¼šæ‰©å±•æ›´å¤šçš„å¾®è°ƒç®—æ³•ï¼Œæ•¬è¯·æœŸå¾…ï¼å…³äºLoRAçš„è¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒè®ºæ–‡â€œ[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)â€ä»¥åŠå¾®è½¯Githubä»“åº“[LoRA](https://github.com/microsoft/LoRA)ã€‚

### å¾®è°ƒè¿‡ç¨‹

#### Step1: ç¯å¢ƒå‡†å¤‡

æ ¹æ®[requirements.txt](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/requirements.txt)å®‰è£…å¯¹åº”çš„ç¯å¢ƒä¾èµ–ã€‚

#### Step2: æ•°æ®å‡†å¤‡
åœ¨dataç›®å½•ä¸‹æä¾›äº†ä¸€ä»½ç”¨äºæ¨¡å‹sftçš„æ•°æ®æ ·ä¾‹ï¼š
- è®­ç»ƒæ•°æ®ï¼š[data/train_sft.csv](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/data/train_sft.csv)
- éªŒè¯æ•°æ®ï¼š[data/dev_sft.csv](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/data/dev_sft.csv)

æ¯ä¸ªcsvæ–‡ä»¶ä¸­åŒ…å«ä¸€åˆ—â€œtextâ€ï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªè®­ç»ƒæ ·ä¾‹ï¼Œæ¯ä¸ªè®­ç»ƒæ ·ä¾‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å°†é—®é¢˜å’Œç­”æ¡ˆç»„ç»‡ä¸ºæ¨¡å‹è¾“å…¥ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è‡ªå®šä¹‰è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ï¼š
```
"<s>Human: "+é—®é¢˜+"\n</s><s>Assistant: "+ç­”æ¡ˆ
```
ä¾‹å¦‚ï¼Œ
```
<s>Human: ç”¨ä¸€å¥è¯æè¿°åœ°çƒä¸ºä»€ä¹ˆæ˜¯ç‹¬ä¸€æ— äºŒçš„ã€‚</s><s>Assistant: å› ä¸ºåœ°çƒæ˜¯ç›®å‰ä¸ºæ­¢å”¯ä¸€å·²çŸ¥å­˜åœ¨ç”Ÿå‘½çš„è¡Œæ˜Ÿã€‚</s>
```

#### Step3: å¾®è°ƒè„šæœ¬

æˆ‘ä»¬æä¾›äº†ç”¨äºå¾®è°ƒçš„è„šæœ¬[train/sft/finetune.sh](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/sft/finetune.sh)ï¼Œé€šè¿‡ä¿®æ”¹è„šæœ¬çš„éƒ¨åˆ†å‚æ•°å®ç°æ¨¡å‹çš„å¾®è°ƒï¼Œå…³äºå¾®è°ƒçš„å…·ä½“ä»£ç è§[train/sft/finetune_clm_lora.py](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/sft/finetune_clm_lora.py)ï¼Œå•æœºå¤šå¡çš„å¾®è°ƒå¯ä»¥é€šè¿‡ä¿®æ”¹è„šæœ¬ä¸­çš„`--include localhost:0`æ¥å®ç°ã€‚


### åŠ è½½å¾®è°ƒæ¨¡å‹
å¾®è°ƒæ¨¡å‹å‚æ•°è§ï¼š[åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹](#åŸºäºllama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹)ï¼ŒLoRAå‚æ•°éœ€è¦å’ŒåŸºç¡€æ¨¡å‹å‚æ•°ç»“åˆä½¿ç”¨ã€‚

é€šè¿‡[PEFT](https://github.com/huggingface/peft)åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å‚æ•°å’Œå¾®è°ƒæ¨¡å‹å‚æ•°ï¼Œä»¥ä¸‹ç¤ºä¾‹ä»£ç ä¸­ï¼Œbase_model_name_or_pathä¸ºé¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ï¼Œfinetune_model_pathä¸ºå¾®è°ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ã€‚

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel,PeftConfig
# ä¾‹å¦‚: finetune_model_path='FlagAlpha/Llama2-Chinese-7b-Chat-LoRA'
finetune_model_path=''  
config = PeftConfig.from_pretrained(finetune_model_path)
# ä¾‹å¦‚: base_model_name_or_path='meta-llama/Llama-2-7b-chat'
tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,use_fast=False)
tokenizer.pad_token = tokenizer.eos_token
model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,device_map='auto',torch_dtype=torch.float16,load_in_8bit=True)
model = PeftModel.from_pretrained(model, finetune_model_path, device_map={"": 0})
model =model.eval()
input_ids = tokenizer(['<s>Human: ä»‹ç»ä¸€ä¸‹åŒ—äº¬\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids.to('cuda')        
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```


<!-- ## ğŸš€ æœªæ¥è®¡åˆ’ -->


## ğŸ„ æ¨¡å‹é‡åŒ–
æˆ‘ä»¬å¯¹ä¸­æ–‡å¾®è°ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œäº†é‡åŒ–ï¼Œæ–¹ä¾¿ä»¥æ›´å°‘çš„è®¡ç®—èµ„æºè¿è¡Œã€‚ç›®å‰å·²ç»åœ¨[Hugging Face](https://huggingface.co/FlagAlpha)ä¸Šä¼ äº†13Bä¸­æ–‡å¾®è°ƒæ¨¡å‹[FlagAlpha/Llama2-Chinese-13b-Chat](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat)çš„4bitå‹ç¼©ç‰ˆæœ¬[FlagAlpha/Llama2-Chinese-13b-Chat-4bit](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit)ï¼Œå…·ä½“è°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š
```python
from transformers import AutoTokenizer
from auto_gptq import AutoGPTQForCausalLM
model = AutoGPTQForCausalLM.from_quantized('FlagAlpha/Llama2-Chinese-13b-Chat-4bit', device="cuda:0")
tokenizer = AutoTokenizer.from_pretrained('FlagAlpha/Llama2-Chinese-13b-Chat-4bit',use_fast=False)
input_ids = tokenizer(['<s>Human: æ€ä¹ˆç™»ä¸Šç«æ˜Ÿ\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids.to('cuda')        
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```

## ğŸš€ æ¨ç†åŠ é€Ÿ
éšç€å¤§æ¨¡å‹å‚æ•°è§„æ¨¡çš„ä¸æ–­å¢é•¿ï¼Œåœ¨æœ‰é™çš„ç®—åŠ›èµ„æºä¸‹ï¼Œæå‡æ¨¡å‹çš„æ¨ç†é€Ÿåº¦é€æ¸å˜ä¸ºä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚å¸¸ç”¨çš„æ¨ç†åŠ é€Ÿæ¡†æ¶åŒ…å« lmdeployã€FasterTransformer å’Œ vLLM ç­‰ã€‚

### lmdeploy
[lmdeploy](https://github.com/InternLM/lmdeploy/) ç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€å‘ï¼Œæ¨ç†ä½¿ç”¨ C++/CUDAï¼Œå¯¹å¤–æä¾› python/gRPC/http æ¥å£å’Œ WebUI ç•Œé¢ï¼Œæ”¯æŒ tensor parallel åˆ†å¸ƒå¼æ¨ç†ã€æ”¯æŒ fp16/weight int4/kv cache int8 é‡åŒ–ã€‚

è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š[inference-speed/GPU/lmdeploy_example](https://github.com/FlagAlpha/Llama2-Chinese/tree/main/inference-speed/GPU/lmdeploy_example)

### FasterTransformer
[FasterTransformer](https://github.com/NVIDIA/FasterTransformer)ç”±NVIDIAå¼€å‘ï¼Œé‡‡ç”¨C++/CUDAç¼–å†™ï¼Œæ”¯æŒåˆ†å¸ƒå¼æ¨ç†ï¼Œtransformerç¼–ç å™¨å’Œè§£ç å™¨å‡å¯è¿›è¡ŒåŠ é€Ÿã€‚
é€šè¿‡FasterTransformerå’Œ[Triton](https://github.com/openai/triton)åŠ é€ŸLLama2æ¨¡å‹æ¨ç†ï¼Œç›®å‰æ”¯æŒFP16æˆ–è€…Int8æ¨ç†ï¼ŒInt4ç›®å‰è¿˜ä¸æ”¯æŒã€‚

è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š[inference-speed/GPU/FasterTransformer_example](https://github.com/FlagAlpha/Llama2-Chinese/tree/main/inference-speed/GPU/FasterTransformer_example)

### vLLM
[vLLM](https://github.com/vllm-project/vllm)ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å¼€å‘ï¼Œæ ¸å¿ƒæŠ€æœ¯æ˜¯PageAttentionï¼Œååé‡æ¯”HuggingFace Transformersé«˜å‡º24å€ã€‚ç›¸è¾ƒä¸FasterTrainsformerï¼ŒvLLMæ›´åŠ çš„ç®€å•æ˜“ç”¨ï¼Œä¸éœ€è¦é¢å¤–è¿›è¡Œæ¨¡å‹çš„è½¬æ¢ï¼Œæ”¯æŒfp16æ¨ç†ã€‚

è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š[inference-speed/GPU/vllm_example](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/inference-speed/GPU/vllm_example/README.md)


## ğŸ¥‡ æ¨¡å‹è¯„æµ‹
ä¸ºäº†èƒ½å¤Ÿæ›´åŠ æ¸…æ™°åœ°äº†è§£Llama2æ¨¡å‹çš„ä¸­æ–‡é—®ç­”èƒ½åŠ›ï¼Œæˆ‘ä»¬ç­›é€‰äº†ä¸€äº›å…·æœ‰ä»£è¡¨æ€§çš„ä¸­æ–‡é—®é¢˜ï¼Œå¯¹Llama2æ¨¡å‹è¿›è¡Œæé—®ã€‚æˆ‘ä»¬æµ‹è¯•çš„æ¨¡å‹åŒ…å«Metaå…¬å¼€çš„Llama2-7B-Chatå’ŒLlama2-13B-Chatä¸¤ä¸ªç‰ˆæœ¬ï¼Œæ²¡æœ‰åšä»»ä½•å¾®è°ƒå’Œè®­ç»ƒã€‚æµ‹è¯•é—®é¢˜ç­›é€‰è‡ª[AtomBulb](https://github.com/AtomEcho/AtomBulb)ï¼Œå…±95ä¸ªæµ‹è¯•é—®é¢˜ï¼ŒåŒ…å«ï¼šé€šç”¨çŸ¥è¯†ã€è¯­è¨€ç†è§£ã€åˆ›ä½œèƒ½åŠ›ã€é€»è¾‘æ¨ç†ã€ä»£ç ç¼–ç¨‹ã€å·¥ä½œæŠ€èƒ½ã€ä½¿ç”¨å·¥å…·ã€äººæ ¼ç‰¹å¾å…«ä¸ªå¤§çš„ç±»åˆ«ã€‚

æµ‹è¯•ä¸­ä½¿ç”¨çš„Promptå¦‚ä¸‹ï¼Œä¾‹å¦‚å¯¹äºé—®é¢˜â€œåˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•â€ï¼š
```
[INST] 
<<SYS>>
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.

The answer always been translate into Chinese language.
<</SYS>>

åˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•
[/INST]
```
Llama2-7B-Chatçš„æµ‹è¯•ç»“æœè§[meta_eval_7B.md](assets/meta_eval_7B.md)ï¼ŒLlama2-13B-Chatçš„æµ‹è¯•ç»“æœè§[meta_eval_13B.md](assets/meta_eval_13B.md)ã€‚

é€šè¿‡æµ‹è¯•æˆ‘ä»¬å‘ç°ï¼ŒMetaåŸå§‹çš„Llama2 Chatæ¨¡å‹å¯¹äºä¸­æ–‡é—®ç­”çš„å¯¹é½æ•ˆæœä¸€èˆ¬ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹éƒ½ä¸èƒ½ç»™å‡ºä¸­æ–‡å›ç­”ï¼Œæˆ–è€…æ˜¯ä¸­è‹±æ–‡æ··æ‚çš„å½¢å¼ã€‚å› æ­¤ï¼ŒåŸºäºä¸­æ–‡æ•°æ®å¯¹Llama2æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œå¾®è°ƒååˆ†å¿…è¦ï¼Œæˆ‘ä»¬çš„ä¸­æ–‡ç‰ˆLlama2æ¨¡å‹ä¹Ÿå·²ç»åœ¨è®­ç»ƒä¸­ï¼Œè¿‘æœŸå°†å¯¹ç¤¾åŒºå¼€æ”¾ã€‚


## ğŸ’ª å¤–å»¶èƒ½åŠ›

é™¤äº†æŒç»­å¢å¼ºå¤§æ¨¡å‹å†…åœ¨çš„çŸ¥è¯†å‚¨å¤‡ã€é€šç”¨ç†è§£ã€é€»è¾‘æ¨ç†å’Œæƒ³è±¡èƒ½åŠ›ç­‰ï¼Œæœªæ¥ï¼Œæˆ‘ä»¬ä¹Ÿä¼šä¸æ–­ä¸°å¯Œå¤§æ¨¡å‹çš„å¤–å»¶èƒ½åŠ›ï¼Œä¾‹å¦‚çŸ¥è¯†åº“æ£€ç´¢ã€è®¡ç®—å·¥å…·ã€WolframAlphaã€æ“ä½œè½¯ä»¶ç­‰ã€‚
æˆ‘ä»¬é¦–å…ˆé›†æˆäº†LangChainæ¡†æ¶ï¼Œå¯ä»¥æ›´æ–¹ä¾¿åœ°åŸºäºLlama2å¼€å‘æ–‡æ¡£æ£€ç´¢ã€é—®ç­”æœºå™¨äººå’Œæ™ºèƒ½ä½“åº”ç”¨ç­‰ï¼Œå…³äºLangChainçš„æ›´å¤šä»‹ç»å‚è§[LangChain](https://github.com/langchain-ai/langchain)ã€‚
### LangChain
é’ˆå¯¹LangChainæ¡†æ¶å°è£…çš„Llama2 LLMç±»è§[examples/llama2_for_langchain.py](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/examples/llama2_for_langchain.py)ï¼Œç®€å•çš„è°ƒç”¨ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
from llama2_for_langchain import Llama2

# è¿™é‡Œä»¥è°ƒç”¨4bité‡åŒ–å‹ç¼©çš„Llama2-Chineseå‚æ•°FlagAlpha/Llama2-Chinese-13b-Chat-4bitä¸ºä¾‹
llm = Llama2(model_name_or_path='FlagAlpha/Llama2-Chinese-13b-Chat-4bit', bit4=True)

while True:
    human_input = input("Human: ")
    response = llm(human_input)
    print(f"Llama2: {response}")
```

## ğŸ ä»£ç æ¨¡å‹
Metaå®˜æ–¹åœ¨2023å¹´8æœˆ24æ—¥å‘å¸ƒäº†å‘å¸ƒäº†Code Llamaï¼ŒåŸºäºä»£ç æ•°æ®å¯¹Llama2è¿›è¡Œäº†å¾®è°ƒï¼Œæä¾›ä¸‰ä¸ªä¸åŒåŠŸèƒ½çš„ç‰ˆæœ¬ï¼šåŸºç¡€æ¨¡å‹ï¼ˆCode Llamaï¼‰ã€Pythonä¸“ç”¨æ¨¡å‹ï¼ˆCode Llama - Pythonï¼‰å’ŒæŒ‡ä»¤è·Ÿéšæ¨¡å‹ï¼ˆCode Llama - Instructï¼‰ï¼ŒåŒ…å«7Bã€13Bã€34Bä¸‰ç§ä¸åŒå‚æ•°è§„æ¨¡ã€‚ä¸åŒæ¨¡å‹èƒ½åŠ›åŒºåˆ«å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š

|  æ¨¡å‹ç±»åˆ«          |        æ¨¡å‹åç§°         | ä»£ç ç»­å†™ | ä»£ç å¡«å…… | æŒ‡ä»¤ç¼–ç¨‹ |
|-----------------------|------------------------|------|------|------|
| Code Llama            | CodeLlama-7b           | âœ…    | âœ…    | âŒ    |
|                       | CodeLlama-13b          | âœ…    | âœ…    | âŒ    |
|                       | CodeLlama-34b          | âœ…    | âŒ    | âŒ    |
| Code Llama - Python   | CodeLlama-7b-Python    | âœ…    | âŒ    | âŒ    |
|                       | CodeLlama-13b-Python   | âœ…    | âŒ    | âŒ    |
|                       | CodeLlama-34b-Python   | âœ…    | âŒ    | âŒ    |
| Code Llama - Instruct | CodeLlama-7b-Instruct  | âŒ    | âœ…    | âœ…    |
|                       | CodeLlama-13b-Instruct | âŒ    | âœ…    | âœ…    |
|                       | CodeLlama-34b-Instruct | âŒ    | âŒ    | âœ…    |

æˆ‘ä»¬æä¾›äº†Code Llamaçš„[å›½å†…ä¸‹è½½é“¾æ¥](#-å›½å†…llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿)ä»¥åŠåœ¨çº¿ä½“éªŒåœ°å€[llama.family](https://llama.family/)ï¼Œå…³äºCode Llamaçš„è¯¦ç»†ä¿¡æ¯å¯ä»¥å‚è€ƒå®˜æ–¹Githubä»“åº“[codellama](https://github.com/facebookresearch/codellama)ã€‚


## ğŸ“– å­¦ä¹ èµ„æ–™
### Metaå®˜æ–¹å¯¹äº[Llama2](https://ai.meta.com/llama)çš„ä»‹ç»
è‡ªä»Metaå…¬å¸å‘å¸ƒç¬¬ä¸€ä»£LLaMAæ¨¡å‹ä»¥æ¥ï¼Œç¾Šé©¼æ¨¡å‹å®¶æ—ç¹è£å‘å±•ã€‚è¿‘æœŸMetaå‘å¸ƒäº†Llama2ç‰ˆæœ¬ï¼Œå¼€æºå¯å•†ç”¨ï¼Œåœ¨æ¨¡å‹å’Œæ•ˆæœä¸Šæœ‰äº†é‡å¤§æ›´æ–°ã€‚Llama2æ€»å…±å…¬å¸ƒäº†7Bã€13Bå’Œ70Bä¸‰ç§å‚æ•°å¤§å°çš„æ¨¡å‹ã€‚ç›¸æ¯”äºLLaMAï¼ŒLlama2çš„è®­ç»ƒæ•°æ®è¾¾åˆ°äº†2ä¸‡äº¿tokenï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä¹Ÿç”±ä¹‹å‰çš„2048å‡çº§åˆ°4096ï¼Œå¯ä»¥ç†è§£å’Œç”Ÿæˆæ›´é•¿çš„æ–‡æœ¬ã€‚Llama2 Chatæ¨¡å‹åŸºäº100ä¸‡äººç±»æ ‡è®°æ•°æ®å¾®è°ƒå¾—åˆ°ï¼Œåœ¨è‹±æ–‡å¯¹è¯ä¸Šè¾¾åˆ°äº†æ¥è¿‘ChatGPTçš„æ•ˆæœã€‚      

### Llamaç›¸å…³è®ºæ–‡
* [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
* [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)
* [Code Llama: Open Foundation Models for Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/)
### Llama2çš„è¯„æµ‹ç»“æœ
<p align="center" width="100%">
<img src="./assets/llama_eval.jpeg" style="width: 100%; display: block; margin: auto;">
</p>


## ğŸ‰ è‡´è°¢

æ„Ÿè°¢åŸå­å›å£°[AtomEcho](https://github.com/AtomEcho)å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼

æ„Ÿè°¢ @xzsGenius å¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„è´¡çŒ®ï¼

æ„Ÿè°¢ @Z Potentialsç¤¾åŒºå¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„æ”¯æŒï¼


## ğŸ¤” é—®é¢˜åé¦ˆ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·åœ¨GitHub Issueä¸­æäº¤ï¼Œåœ¨æäº¤é—®é¢˜ä¹‹å‰ï¼Œè¯·å…ˆæŸ¥é˜…ä»¥å¾€çš„issueæ˜¯å¦èƒ½è§£å†³ä½ çš„é—®é¢˜ã€‚

ç¤¼è²Œåœ°æå‡ºé—®é¢˜ï¼Œæ„å»ºå’Œè°çš„è®¨è®ºç¤¾åŒºã€‚

åŠ å…¥[é£ä¹¦çŸ¥è¯†åº“](https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink)ï¼Œä¸€èµ·å…±å»ºç¤¾åŒºæ–‡æ¡£ã€‚

åŠ å…¥å¾®ä¿¡ç¾¤è®¨è®ºğŸ˜ğŸ˜

<p align="center" width="100%">
<img src="./assets/wechat.jpeg" alt="Wechat" style="width: 100%; display: block; margin: auto;">
</p>

<p align="center" width="100%">
<img src="https://api.star-history.com/svg?repos=FlagAlpha/Llama2-Chinese&type=Date" alt="Wechat" style="width: 100%; display: block; margin: auto;">
</p>
