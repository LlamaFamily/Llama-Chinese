<p align="left">
    <a href="README_EN.md">English</a> ï½œ ä¸­æ–‡
</p>

<h1 align="center">
  Llamaä¸­æ–‡ç¤¾åŒº
</h1>
<p align="center" width="100%">
  <img src="assets/llama.jpg" alt="Llama" style="width: 20%; display: block; margin: auto;"></a>
</p>
<p align="center">
  <font face="é»‘ä½“" color=orange size="6"> Llama3ä½“éªŒå’Œå¾®è°ƒå·²å¼€æ”¾ï¼Œæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ </font>
</p>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/FlagAlpha" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://www.modelscope.cn/organization/FlagAlpha/" target="_blank">ModelScope</a> â€¢ âœ¡ï¸ <a href="https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat" target="_blank">WiseModel</a>
</p> 

<p align="center">
  <a href="https://llama.family">Llama3.1 åœ¨çº¿ä½“éªŒï¼ˆåŒ…å«Llama2ï¼‰ï¼šhttps://llama.family</a>
</p>
<p align="center">
  <a href="https://huggingface.co/FlagAlpha/Atom-7B-Chat">åŸºäºLlamaçš„å¼€æºä¸­æ–‡é¢„è®­ç»ƒå¤§æ¨¡å‹Atom</a>
</p>

</br></br>


## ğŸ—‚ï¸ ç›®å½•
- [ğŸ“Œ Llamaä¸­æ–‡ç¤¾åŒº](#-llamaä¸­æ–‡ç¤¾åŒº)
  * [ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlamaä¸­æ–‡ç¤¾åŒº](#-ç¤¾åŒºä»‹ç»llamaä¸­æ–‡ç¤¾åŒº)
  * [ğŸ“¢ æœ€æ–°åŠ¨æ€](#-æœ€æ–°åŠ¨æ€)
  * [ğŸ¤— æ¨¡å‹](#-æ¨¡å‹)
    + [ğŸ¤— ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom-7B](#-ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹atom)
    + [ğŸ¤— Llama3å®˜æ–¹æ¨¡å‹](#llama3å®˜æ–¹æ¨¡å‹)
    + [ğŸ¤— Llama3ä¸­æ–‡å¾®è°ƒæ¨¡å‹](#llama3ä¸­æ–‡å¾®è°ƒæ¨¡å‹)
    + [ğŸ¤— Llama2å®˜æ–¹æ¨¡å‹](#llama2å®˜æ–¹æ¨¡å‹)
    + [ğŸ¤— Llama2ä¸­æ–‡å¾®è°ƒæ¨¡å‹](#llama2ä¸­æ–‡å¾®è°ƒæ¨¡å‹)
  * [ğŸŒŸ ç¤¾åŒºèµ„æº](#ç¤¾åŒºèµ„æº)


- [ğŸ“Œ å¦‚ä½•ä½¿ç”¨Llamaæ¨¡å‹?](#-å¦‚ä½•ä½¿ç”¨llamaæ¨¡å‹)
  - [å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Anaconda](#å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨anaconda)
  - [å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Docker](#å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨docker)
  - [å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨llama.cpp](#å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨llamacpp)
  - [å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨gradio](#å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨gradio)
  - [å¿«é€Ÿä¸Šæ‰‹-æ„å»ºAPIæœåŠ¡](#å¿«é€Ÿä¸Šæ‰‹-æ„å»ºapiæœåŠ¡)
  - [å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨ollamaè¿è¡Œ](#å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨ollamaè¿è¡Œ)

+ [ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ](#-æ¨¡å‹é¢„è®­ç»ƒ)
+ [ğŸ’¡ æ¨¡å‹å¾®è°ƒ](#-æ¨¡å‹å¾®è°ƒ)
  - [Step1: ç¯å¢ƒå‡†å¤‡](#step1-ç¯å¢ƒå‡†å¤‡)
  - [Step2: æ•°æ®å‡†å¤‡](#step2-æ•°æ®å‡†å¤‡)
  - [Step3: å¾®è°ƒè„šæœ¬](#step3-å¾®è°ƒè„šæœ¬)
    * [LoRAå¾®è°ƒ](#loraå¾®è°ƒ)
    * [å…¨é‡å‚æ•°å¾®è°ƒ](#å…¨é‡å‚æ•°å¾®è°ƒ)
  - [Step4: åŠ è½½å¾®è°ƒæ¨¡å‹](#step4-åŠ è½½å¾®è°ƒæ¨¡å‹)
    * [LoRAå¾®è°ƒ](#loraå¾®è°ƒ-1)
    * [å…¨é‡å‚æ•°å¾®è°ƒ](#å…¨é‡å‚æ•°å¾®è°ƒ-1)
+ [ğŸ„ æ¨¡å‹é‡åŒ–](#-æ¨¡å‹é‡åŒ–)

+ [ğŸš€ éƒ¨ç½²åŠ é€Ÿ](#-éƒ¨ç½²åŠ é€Ÿ)
  - [TensorRT-LLM](#tensorrt-llm)
  - [vLLM](#vllm)  
  - [JittorLLMs](#jittorllms)
  - [lmdeploy](#lmdeploy)

+ [ğŸ’ª å¤–å»¶èƒ½åŠ›](#-å¤–å»¶èƒ½åŠ›)
  - [LangChain](#langchain)
    
* [ğŸ¥‡ æ¨¡å‹è¯„æµ‹](#-æ¨¡å‹è¯„æµ‹)
  + [Llama2å’ŒLlama3å¯¹æ¯”è¯„æµ‹](#llama2å’Œllama3å¯¹æ¯”è¯„æµ‹)
  + [Llama3æ¨¡å‹è¯„æµ‹](#llama3æ¨¡å‹è¯„æµ‹)
  + [Llama2æ¨¡å‹è¯„æµ‹](#llama2æ¨¡å‹è¯„æµ‹)

* [ğŸ“– å­¦ä¹ ä¸­å¿ƒ](#-å­¦ä¹ ä¸­å¿ƒ)
    + [Llama3](#llama3)
    + [Llama2](#llama2)
      - [Metaå®˜æ–¹å¯¹äºLlama2çš„ä»‹ç»](#metaå®˜æ–¹å¯¹äºllama2çš„ä»‹ç»)
    + [Llamaç›¸å…³è®ºæ–‡](#llamaç›¸å…³è®ºæ–‡)

- [ğŸ“Œ å…¶å®ƒ](#-å…¶å®ƒ)
  * [ğŸ‰ è‡´è°¢](#-è‡´è°¢)
  * [ğŸ¤” é—®é¢˜åé¦ˆ](#-é—®é¢˜åé¦ˆ)

## ğŸ“Œ Llamaä¸­æ–‡ç¤¾åŒº

### ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šllamaä¸­æ–‡ç¤¾åŒº

æ¬¢è¿æ¥åˆ°Llamaä¸­æ–‡ç¤¾åŒºï¼æˆ‘ä»¬æ˜¯ä¸€ä¸ªä¸“æ³¨äºLlamaæ¨¡å‹åœ¨ä¸­æ–‡æ–¹é¢çš„ä¼˜åŒ–å’Œä¸Šå±‚å»ºè®¾çš„é«˜çº§æŠ€æœ¯ç¤¾åŒºã€‚
**å·²ç»åŸºäºå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®ï¼Œä»é¢„è®­ç»ƒå¼€å§‹å¯¹Llama2æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§ã€Doneã€‘**ã€‚**æ­£åœ¨å¯¹Llama3æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§ã€Doingã€‘**
æˆ‘ä»¬çƒ­å¿±æ¬¢è¿å¯¹å¤§æ¨¡å‹LLMå……æ»¡çƒ­æƒ…çš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥æˆ‘ä»¬çš„è¡Œåˆ—ã€‚

<details>

#### ä¸ºä»€ä¹ˆé€‰æ‹©Llamaä¸­æ–‡ç¤¾åŒºï¼Ÿ
ğŸš€ **é«˜çº§å·¥ç¨‹å¸ˆå›¢é˜Ÿæ”¯æŒ**ï¼šç¤¾åŒºæœ‰ä¸€æ‰¹ä¸“æ³¨ä¸ºå¤§å®¶æœåŠ¡çš„NLPé«˜çº§å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬æœ‰ç€å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒå’Œä¸°å¯Œçš„ç»éªŒï¼Œä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŒ‡å¯¼å’Œå¸®åŠ©ã€‚

ğŸ¯ **ä¸­æ–‡ä¼˜åŒ–**ï¼šæˆ‘ä»¬è‡´åŠ›äºåœ¨Llamaæ¨¡å‹çš„ä¸­æ–‡å¤„ç†æ–¹é¢è¿›è¡Œä¼˜åŒ–ï¼Œæ¢ç´¢é€‚ç”¨äºä¸­æ–‡çš„æœ€ä½³å®è·µï¼Œä»¥æå‡å…¶æ€§èƒ½å’Œé€‚åº”æ€§ã€æ”¯æŒLlama2ã€Llama3ã€‘ã€‚

ğŸ’¡ **åˆ›æ–°äº¤æµ**ï¼šæˆ‘ä»¬æ‹¥æœ‰ä¸€æ”¯å¯Œæœ‰åˆ›é€ åŠ›å’Œç»éªŒçš„ç¤¾åŒºæˆå‘˜å›¢é˜Ÿï¼Œå®šæœŸç»„ç»‡çº¿ä¸Šæ´»åŠ¨ã€æŠ€æœ¯ç ”è®¨å’Œç»éªŒåˆ†äº«ï¼Œä¿ƒè¿›æˆå‘˜é—´çš„åˆ›æ–°äº¤æµã€‚

ğŸŒ **å…¨çƒè”ç»“**ï¼šæˆ‘ä»¬æ¬¢è¿æ¥è‡ªä¸–ç•Œå„åœ°çš„å¼€å‘è€…åŠ å…¥ç¤¾åŒºï¼Œæ„å»ºä¸€ä¸ªå¼€æ”¾ã€å¤šå…ƒåŒ–çš„å­¦ä¹ å’Œäº¤æµå¹³å°ã€‚

ğŸ¤ **å¼€æ”¾å…±äº«**ï¼šæˆ‘ä»¬é¼“åŠ±ç¤¾åŒºæˆå‘˜å¼€æºåˆ†äº«ä»£ç å’Œæ¨¡å‹ï¼Œæ¨åŠ¨åˆä½œå…±èµ¢ï¼Œå…±åŒä¿ƒè¿›ä¸­æ–‡NLPæŠ€æœ¯çš„å‘å±•ã€‚

#### ç¤¾åŒºæ´»åŠ¨
ğŸ—“ï¸ **çº¿ä¸Šè®²åº§**ï¼šé‚€è¯·è¡Œä¸šå†…ä¸“å®¶è¿›è¡Œçº¿ä¸Šè®²åº§ï¼Œåˆ†äº«Llamaåœ¨ä¸­æ–‡NLPé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯å’Œåº”ç”¨ï¼Œæ¢è®¨å‰æ²¿ç ”ç©¶æˆæœã€‚

ğŸ’» **é¡¹ç›®å±•ç¤º**ï¼šæˆå‘˜å¯å±•ç¤ºè‡ªå·±åœ¨Llamaä¸­æ–‡ä¼˜åŒ–æ–¹é¢çš„é¡¹ç›®æˆæœï¼Œè·å¾—åé¦ˆå’Œå»ºè®®ï¼Œä¿ƒè¿›é¡¹ç›®åä½œã€‚

ğŸ“š **å­¦ä¹ èµ„æº**ï¼šç¤¾åŒºç»´æŠ¤ä¸°å¯Œçš„å­¦ä¹ èµ„æ–™åº“ï¼ŒåŒ…æ‹¬æ•™ç¨‹ã€æ–‡æ¡£å’Œè®ºæ–‡è§£è¯»ï¼Œä¸ºæˆå‘˜æä¾›å…¨é¢çš„å­¦ä¹ æ”¯æŒã€‚

ğŸ“ **è®ºæ–‡è§£è¯»**ï¼šç¤¾åŒºæˆå‘˜å…±åŒè§£è¯»ä¸Llamaç›¸å…³çš„æœ€æ–°ç ”ç©¶è®ºæ–‡ï¼Œæ·±å…¥ç†è§£å‰æ²¿ç®—æ³•å’Œæ–¹æ³•ã€‚

ğŸ‰ **ä¸»é¢˜æ´»åŠ¨**ï¼šå®šæœŸä¸¾åŠå„ç±»ä¸»é¢˜æ´»åŠ¨ï¼ŒåŒ…æ‹¬æŒ‘æˆ˜èµ›ã€é»‘å®¢é©¬æ‹‰æ¾å’ŒæŠ€æœ¯æ²™é¾™ï¼Œè®©ç¤¾åŒºæˆå‘˜åœ¨è½»æ¾æ„‰å¿«çš„æ°›å›´ä¸­äº¤æµå’Œå­¦ä¹ ã€‚

ğŸŒŸ **å¥–åŠ±è®¡åˆ’**ï¼šæˆ‘ä»¬è®¾ç«‹å¥–åŠ±è®¡åˆ’ï¼Œå¯¹ç¤¾åŒºä¸­ç§¯æå‚ä¸ã€è´¡çŒ®ä¼˜ç§€çš„æˆå‘˜ç»™äºˆè£èª‰å’Œå¥–åŠ±ï¼Œæ¿€åŠ±æ›´å¤šä¼˜ç§€äººæ‰çš„åŠ å…¥ã€‚

ğŸ“ˆ **æŠ€æœ¯å’¨è¯¢**ï¼šæˆ‘ä»¬æä¾›æŠ€æœ¯å’¨è¯¢æœåŠ¡ï¼Œè§£ç­”æ‚¨åœ¨Llamaå¼€å‘å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ï¼ŒåŠ©æ‚¨å¿«é€Ÿæ”»å…‹éš¾å…³ã€‚

ğŸš€ **é¡¹ç›®åˆä½œ**ï¼šé¼“åŠ±æˆå‘˜é—´çš„é¡¹ç›®åˆä½œï¼Œå…±åŒæ¢ç´¢Llamaåœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ï¼Œæ‰“é€ åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚


#### ç«‹å³åŠ å…¥æˆ‘ä»¬ï¼
ğŸ“š **æ„¿æ™¯**ï¼šæ— è®ºæ‚¨æ˜¯å¯¹Llamaå·²æœ‰ç ”ç©¶å’Œåº”ç”¨ç»éªŒçš„ä¸“ä¸šå¼€å‘è€…ï¼Œè¿˜æ˜¯å¯¹Llamaä¸­æ–‡ä¼˜åŒ–æ„Ÿå…´è¶£å¹¶å¸Œæœ›æ·±å…¥æ¢ç´¢çš„æ–°æ‰‹ï¼Œæˆ‘ä»¬éƒ½çƒ­åˆ‡æœŸå¾…æ‚¨çš„åŠ å…¥ã€‚åœ¨Llamaä¸­æ–‡ç¤¾åŒºï¼Œæ‚¨å°†æœ‰æœºä¼šä¸è¡Œä¸šå†…é¡¶å°–äººæ‰å…±åŒäº¤æµï¼Œæºæ‰‹æ¨åŠ¨ä¸­æ–‡NLPæŠ€æœ¯çš„è¿›æ­¥ï¼Œå¼€åˆ›æ›´åŠ ç¾å¥½çš„æŠ€æœ¯æœªæ¥ï¼

ğŸ”— **æ¸©é¦¨æç¤º**ï¼šæœ¬ç¤¾åŒºä¸ºä¸“ä¸šæŠ€æœ¯äº¤æµå¹³å°ï¼Œæˆ‘ä»¬çƒ­åˆ‡æœŸæœ›å¿—åŒé“åˆçš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥ã€‚è¯·éµå®ˆç¤¾åŒºå‡†åˆ™ï¼Œå…±åŒç»´æŠ¤ç§¯æå‘ä¸Šçš„å­¦ä¹ æ°›å›´ã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£å’Œæ”¯æŒï¼

</details>

### ğŸ“¢ æœ€æ–°åŠ¨æ€

ã€æœ€æ–°ã€‘2024å¹´07æœˆ24æ—¥ï¼šå¼€æºæœ€å¼º[Llama 3.1](https://llama.meta.com/docs/overview)æ¨¡å‹å‘å¸ƒï¼ŒåŒ…å«8Bã€70Bå’Œ405Bï¼

ã€æœ€æ–°ã€‘2024å¹´07æœˆ16æ—¥ï¼š[ç¤¾åŒºè®ºå›](https://forum.llamafamily.cn/)ä¸Šçº¿ï¼Œæœ‰å¤§æ¨¡å‹é—®é¢˜ï¼Œå°±æ‰¾Llamaä¸­æ–‡ç¤¾åŒºï¼

ã€æœ€æ–°ã€‘2024å¹´05æœˆ15æ—¥ï¼šæ”¯æŒollamaè¿è¡ŒLlama3-Chinese-8B-Instructã€Atom-7B-Chatï¼Œ[è¯¦ç»†ä½¿ç”¨æ–¹æ³•](https://github.com/LlamaFamily/Llama-Chinese?tab=readme-ov-file#%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-%E4%BD%BF%E7%94%A8ollama%E8%BF%90%E8%A1%8C)ã€‚

ã€æœ€æ–°ã€‘2024å¹´04æœˆ23æ—¥ï¼šç¤¾åŒºå¢åŠ äº†llama3 8Bä¸­æ–‡å¾®è°ƒæ¨¡å‹[Llama3-Chinese-8B-Instruct](https://github.com/LlamaFamily/Llama-Chinese?tab=readme-ov-file#llama3%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B)ä»¥åŠå¯¹åº”çš„[å…è´¹APIè°ƒç”¨](https://llama.family/docs/chat-completion-v1)ã€‚
 
ã€æœ€æ–°ã€‘2024å¹´04æœˆ19æ—¥ï¼šç¤¾åŒºå¢åŠ äº†llama3 8Bã€llama3 70B[åœ¨çº¿ä½“éªŒé“¾æ¥](https://llama.family/chat/#/)ã€‚

ã€æœ€æ–°ã€‘2024å¹´04æœˆ14æ—¥ï¼šç¤¾åŒºæ›´æ–°äº†å››ä¸ªä¸“å®¶è§’è‰²ï¼šå¿ƒç†å’¨è¯¢å¸ˆã€ç¾Šé©¼å¤¸å¤¸ ã€å¾‹å¸ˆã€åŒ»ç”Ÿã€‚é“¾æ¥ï¼š[è§’è‰²role](https://llama.family/tools/#/agent)ã€‚

ã€æœ€æ–°ã€‘2024å¹´04æœˆ10æ—¥ï¼šAtom-7B-Chat æ¨¡å‹å›ç­”å†…å®¹ç›¸è¾ƒä¹‹å‰æ›´ä¸ºä¸°å¯Œã€å¢å¼ºäº†æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›å’Œå›ç­”ç¨³å®šæ€§ã€ä¼˜åŒ–äº†ppoçš„å¥–åŠ±æ¨¡å‹ã€‚ä¸‹è½½é“¾æ¥[modelscope](https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat)ã€[Huggingface](https://huggingface.co/FlagAlpha/Atom-7B-Chat)ã€‚

ã€æœ€æ–°ã€‘2024å¹´04æœˆ01æ—¥ï¼šç¤¾åŒºä¸Šçº¿äº†Llamaä¸­æ–‡[åº”ç”¨å¹³å°](https://llama.family/store)ï¼›åŒæ—¶å¦‚æœä½ æœ‰ä¼˜ç§€çš„çš„åº”ç”¨éœ€è¦æ¨å¹¿å¯ä»¥å¡«å†™[ç”³è¯·è¡¨](https://atomecho.feishu.cn/share/base/form/shrcnFqpN71OmBoXDCT6y0TQgIc)ã€‚

ã€æœ€æ–°ã€‘2024å¹´03æœˆ08æ—¥ï¼šå¼€æ”¾äº†å…è´¹APIä¾›å¤§å®¶ä½¿ç”¨ï¼ŒåŒ…å«ï¼ˆAtom-1B,7B,13B 3ç§ä¸­æ–‡å¤§æ¨¡å‹ï¼‰[APIä½¿ç”¨é“¾æ¥](https://llama.family/docs/chat-completion-v1)

ã€æœ€æ–°ã€‘2024å¹´04æœˆ14æ—¥ï¼šç¤¾åŒºæ›´æ–°äº†å››ä¸ªä¸“å®¶è§’è‰²ï¼šå¿ƒç†å’¨è¯¢å¸ˆã€ç¾Šé©¼å¤¸å¤¸ ã€å¾‹å¸ˆã€åŒ»ç”Ÿã€‚é“¾æ¥ï¼š[è§’è‰²role](https://llama.family/tools/#/agent)ã€‚

ã€æœ€æ–°ã€‘2024å¹´04æœˆ10æ—¥ï¼šAtom-7B-Chat æ¨¡å‹å›ç­”å†…å®¹ç›¸è¾ƒä¹‹å‰æ›´ä¸ºä¸°å¯Œã€å¢å¼ºäº†æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›å’Œå›ç­”ç¨³å®šæ€§ã€ä¼˜åŒ–äº†ppoçš„å¥–åŠ±æ¨¡å‹ã€‚ä¸‹è½½é“¾æ¥[modelscope](https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat)ã€[Huggingface](https://huggingface.co/FlagAlpha/Atom-7B-Chat)ã€‚

ã€æœ€æ–°ã€‘2024å¹´04æœˆ01æ—¥ï¼šç¤¾åŒºä¸Šçº¿äº†Llamaä¸­æ–‡[åº”ç”¨å¹³å°](https://llama.family/store)ï¼›åŒæ—¶å¦‚æœä½ æœ‰ä¼˜ç§€çš„çš„åº”ç”¨éœ€è¦æ¨å¹¿å¯ä»¥å¡«å†™[ç”³è¯·è¡¨](https://atomecho.feishu.cn/share/base/form/shrcnFqpN71OmBoXDCT6y0TQgIc)ã€‚

ã€æœ€æ–°ã€‘2024å¹´03æœˆ28æ—¥ï¼š[ç¤¾åŒºå…è´¹å…¬å¼€è¯¾](https://mp.weixin.qq.com/s/CsturoU1pOX11CqVnZgu2A)ã€‚

ã€æœ€æ–°ã€‘2024å¹´03æœˆ08æ—¥ï¼šå¼€æ”¾äº†å…è´¹APIä¾›å¤§å®¶ä½¿ç”¨ï¼ŒåŒ…å«ï¼ˆAtom-1B,7B,13B 3ç§ä¸­æ–‡å¤§æ¨¡å‹ï¼‰[APIä½¿ç”¨é“¾æ¥](https://llama.family/docs/chat-completion-v1)

ã€æœ€æ–°ã€‘2023å¹´10æœˆ8æ—¥ï¼šæ–°å¢æ¸…åå¤§å­¦JittorLLMsçš„æ¨ç†åŠ é€ŸåŠŸèƒ½[JittorLLMs](#jittorllms)ï¼

<details>

- 2023å¹´9æœˆ12æ—¥ï¼šæ›´æ–°é¢„è®­ç»ƒç‰ˆæœ¬[Atom-7B](https://huggingface.co/FlagAlpha/Atom-7B)å’Œå¯¹è¯ç‰ˆæœ¬[Atom-7B-Chat](https://huggingface.co/FlagAlpha/Atom-7B-Chat)æ¨¡å‹å‚æ•°ï¼Œæœ€æ–°çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®é‡ä¸º2.7TB tokenï¼Œè®­ç»ƒè¿›ç¨‹è§[llama.family](https://llama.family/)ï¼

- 2023å¹´9æœˆ2æ—¥ï¼šæ–°å¢æ¨¡å‹[é¢„è®­ç»ƒä»£ç ](#-æ¨¡å‹é¢„è®­ç»ƒ)å’Œ[å…¨é‡å‚æ•°å¾®è°ƒä»£ç ](#-æ¨¡å‹å¾®è°ƒ)ï¼
  
- 2023å¹´8æœˆ28æ—¥ï¼šå‘å¸ƒåŸºäºLlama2è¿›è¡Œä¸­æ–‡é¢„è®­ç»ƒçš„å¼€æºå¤§æ¨¡å‹[Atom-7B](https://huggingface.co/FlagAlpha/Atom-7B)ï¼Œå¹¶å°†æŒç»­æ›´æ–°ï¼Œè¯¦æƒ…å‚è€ƒ[ç¤¾åŒºå…¬ä¼—å·æ–‡ç« ](https://mp.weixin.qq.com/s/Bdx0JTVh1kgPn5ydYxIkEw)ï¼

- 2023å¹´8æœˆ26æ—¥ï¼šæä¾›[FastAPI](#fastapiæ¥å£æ­å»º)æ¥å£æ­å»ºè„šæœ¬ï¼

- 2023å¹´8æœˆ26æ—¥ï¼šæä¾›å°†MetaåŸå§‹æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºå…¼å®¹Hugging Faceçš„[æ ¼å¼è½¬åŒ–è„šæœ¬](https://github.com/LlamaFamily/Llama-Chinese/blob/main/scripts/convert2hf/README.md)ï¼

- 2023å¹´8æœˆ26æ—¥ï¼šæ–°å¢[Code Llama](#-ä»£ç æ¨¡å‹)æ¨¡å‹ï¼

- 2023å¹´8æœˆ15æ—¥ï¼šæ–°å¢[PEFTåŠ è½½å¾®è°ƒæ¨¡å‹å‚æ•°](#åŠ è½½å¾®è°ƒæ¨¡å‹)çš„ä»£ç ç¤ºä¾‹ï¼

- 2023å¹´8æœˆ14æ—¥ï¼š[å¤§æ¨¡å‹æ•°æ®å…±äº«è®­ç»ƒå¹³å°](https://llama.family)ä¸Šçº¿ï¼Œæ²¡æœ‰ç®—åŠ›ä¹Ÿèƒ½å‚ä¸å¤§æ¨¡å‹è®­ç»ƒï¼Œç¤¾åŒºæ¯ä½æˆå‘˜è´¡çŒ®çš„æ•°æ®éƒ½å°†å†³å®šæ¨¡å‹èƒ½åŠ›çš„æœªæ¥èµ°å‘ï¼

- 2023å¹´8æœˆ3æ—¥ï¼šæ–°å¢FasterTransformerå’ŒvLLMçš„GPU[æ¨ç†åŠ é€Ÿ](#-æ¨ç†åŠ é€Ÿ)æ”¯æŒï¼

- 2023å¹´7æœˆ31æ—¥ï¼šã€é‡ç£…ã€‘å›½å†…é¦–ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„Llama2ä¸­æ–‡å¤§æ¨¡å‹å‘å¸ƒï¼è¯¦æƒ…å‚è§[ç¤¾åŒºå…¬ä¼—å·æ–‡ç« ](https://mp.weixin.qq.com/s/lExUU7z_MvgJ7tzQPF8tUQ)

- 2023å¹´7æœˆ28æ—¥ï¼šé€šè¿‡[Dockeréƒ¨ç½²](#dockeréƒ¨ç½²é—®ç­”æ¥å£)é—®ç­”æ¥å£ï¼

- 2023å¹´7æœˆ27æ—¥ï¼šæ–°å¢[LangChain](#langchain)æ”¯æŒï¼

- 2023å¹´7æœˆ26æ—¥ï¼šæ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°çš„[4bité‡åŒ–å‹ç¼©ç‰ˆæœ¬](#-æ¨¡å‹é‡åŒ–)ï¼

- 2023å¹´7æœˆ25æ—¥ï¼šç¤¾åŒºå¾®ä¿¡å…¬ä¼—å·â€œLlamaä¸­æ–‡ç¤¾åŒºâ€æ¬¢è¿å¤§å®¶å…³æ³¨ï¼Œè·å–æœ€æ–°åˆ†äº«å’ŒåŠ¨æ€ï¼

- 2023å¹´7æœˆ24æ—¥ï¼š[FlagAlpha](https://huggingface.co/FlagAlpha)æ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°ï¼

- 2023å¹´7æœˆ24æ—¥ï¼š[llama.family](https://llama.family/)æ–°å¢Llama2-70Båœ¨çº¿ä½“éªŒï¼

- 2023å¹´7æœˆ23æ—¥ï¼šLlama2ä¸­æ–‡å¾®è°ƒå‚æ•°å‘å¸ƒè‡³Hugging Faceä»“åº“[FlagAlpha](https://huggingface.co/FlagAlpha)ï¼

- 2023å¹´7æœˆ22æ—¥ï¼šLlama2åœ¨çº¿ä½“éªŒé“¾æ¥[llama.family](https://llama.family/)ä¸Šçº¿ï¼ŒåŒæ—¶åŒ…å«MetaåŸç‰ˆå’Œä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼

- 2023å¹´7æœˆ21æ—¥ï¼šè¯„æµ‹äº†MetaåŸå§‹ç‰ˆLlama2 Chatæ¨¡å‹çš„[ä¸­æ–‡é—®ç­”èƒ½åŠ›](#-æ¨¡å‹è¯„æµ‹)ï¼

- 2023å¹´7æœˆ21æ—¥ï¼šæ–°å¢Llama2æ¨¡å‹çš„Hugging Faceç‰ˆæœ¬å›½å†…ä¸‹è½½åœ°å€ï¼

- 2023å¹´7æœˆ20æ—¥ï¼šæ–°å¢[é£ä¹¦çŸ¥è¯†åº“æ–‡æ¡£](https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink)ï¼Œæ¬¢è¿å¤§å®¶ä¸€èµ·å…±å»ºï¼

- 2023å¹´7æœˆ20æ—¥ï¼šå›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼

- 2023å¹´7æœˆ19æ—¥ï¼šæ­£å¼å¯åŠ¨Llama2æ¨¡å‹çš„ä¸­æ–‡é¢„è®­ç»ƒï¼Œå…³æ³¨æˆ‘ä»¬è·å–å®æ—¶åŠ¨æ€ï¼

- 2023å¹´7æœˆ19æ—¥ï¼šLlama2å›½å†…ä¸‹è½½åœ°å€æ­£åœ¨å¯åŠ¨ï¼Œæ•¬è¯·æœŸå¾…ï¼

- 2023å¹´7æœˆ19æ—¥ï¼šå¼€å¯Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ï¼

</details>


### ğŸ¤— æ¨¡å‹

#### ğŸ”µ ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom

**åŸå­å¤§æ¨¡å‹Atom**ç”±Llamaä¸­æ–‡ç¤¾åŒºå’ŒåŸå­å›å£°è”åˆæ‰“é€ ã€‚

|  ç±»åˆ«  | æ¨¡å‹åç§°        | ğŸ¤—æ¨¡å‹åŠ è½½åç§°                  | ä¸‹è½½åœ°å€                                                     |
| --------------- | --------------- | ------------------------------ | ------------------------------------------------------------ |
|  é¢„è®­ç»ƒ  | Atom-7B  | FlagAlpha/Atom-7B  | [HuggingFace](https://huggingface.co/FlagAlpha/Atom-7B) \| [ModelScope](https://modelscope.cn/models/FlagAlpha/Atom-7B) \| [WiseModel](https://wisemodel.cn/models/FlagAlpha/Atom-7B) |
|  Chat  | Atom-7B-Chat  | FlagAlpha/Atom-7B-Chat  | [HuggingFace](https://huggingface.co/FlagAlpha/Atom-7B-Chat) \| [ModelScope](https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat) \| [WiseModel](https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat)|

Atomç³»åˆ—æ¨¡å‹åŒ…å«Atom-13Bã€Atom-7Bå’ŒAtom-1Bï¼ŒåŸºäºLlama2åšäº†ä¸­æ–‡èƒ½åŠ›çš„æŒç»­ä¼˜åŒ–ã€‚Atom-7Bå’ŒAtom-7B-Chatç›®å‰å·²å®Œå…¨å¼€æºï¼Œæ”¯æŒå•†ç”¨ï¼Œå¯åœ¨[Hugging Face](https://huggingface.co/FlagAlpha)ä»“åº“è·å–æ¨¡å‹ï¼Œè¯¦æƒ…è§[Atom-7Bä¸‹è½½](#åŸºäºllama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹atom)ã€‚Atomå¤§æ¨¡å‹é’ˆå¯¹ä¸­æ–‡åšäº†ä»¥ä¸‹ä¼˜åŒ–ï¼š

- å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ

åŸå­å¤§æ¨¡å‹Atomåœ¨Llama2çš„åŸºç¡€ä¸Šï¼Œé‡‡ç”¨å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®è¿›è¡ŒæŒç»­é¢„è®­ç»ƒï¼ŒåŒ…å«ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ã€é‡‘èæ•°æ®ã€æ³•å¾‹æ•°æ®ã€åŒ»ç–—æ•°æ®ã€ä»£ç æ•°æ®ã€ä¸“ä¸šè®ºæ–‡æ•°æ®ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç«èµ›æ•°æ®é›†ç­‰ï¼Œè¯¦è§[ğŸ“ æ•°æ®æ¥æº](#-æ•°æ®æ¥æº)ã€‚

åŒæ—¶å¯¹åºå¤§çš„æ•°æ®è¿›è¡Œäº†è¿‡æ»¤ã€æ‰“åˆ†ã€å»é‡ï¼Œç­›é€‰å‡ºè¶…è¿‡1T tokençš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼ŒæŒç»­ä¸æ–­åŠ å…¥è®­ç»ƒè¿­ä»£ä¸­ã€‚

- æ›´é«˜æ•ˆçš„ä¸­æ–‡è¯è¡¨
ä¸ºäº†æé«˜ä¸­æ–‡æ–‡æœ¬å¤„ç†çš„æ•ˆç‡ï¼Œæˆ‘ä»¬é’ˆå¯¹Llama2æ¨¡å‹çš„è¯è¡¨è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åŸºäºæ•°ç™¾Gçš„ä¸­æ–‡æ–‡æœ¬ï¼Œåœ¨è¯¥æ¨¡å‹è¯è¡¨çš„åŸºç¡€ä¸Šæ‰©å±•è¯åº“è‡³65,000ä¸ªå•è¯ã€‚ç»è¿‡æµ‹è¯•ï¼Œæˆ‘ä»¬çš„æ”¹è¿›ä½¿å¾—ä¸­æ–‡ç¼–ç /è§£ç é€Ÿåº¦æé«˜äº†çº¦350ï¼…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ‰©å¤§äº†ä¸­æ–‡å­—ç¬¦é›†çš„è¦†ç›–èŒƒå›´ï¼ŒåŒ…æ‹¬æ‰€æœ‰emojiç¬¦å·ğŸ˜Šã€‚è¿™ä½¿å¾—ç”Ÿæˆå¸¦æœ‰è¡¨æƒ…ç¬¦å·çš„æ–‡ç« æ›´åŠ é«˜æ•ˆã€‚

- è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ‰©å±•
Atomå¤§æ¨¡å‹é»˜è®¤æ”¯æŒ4Kä¸Šä¸‹æ–‡ï¼Œåˆ©ç”¨ä½ç½®æ’å€¼PIå’ŒNeural Tangent Kernel ï¼ˆNTKï¼‰æ–¹æ³•ï¼Œç»è¿‡å¾®è°ƒå¯ä»¥å°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å¢åˆ°32Kã€‚

- ğŸ“ ä¸­æ–‡æ•°æ®

æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ•°æ®æ¥ä¼˜åŒ–Llama2çš„ä¸­æ–‡èƒ½åŠ›:

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| ç½‘ç»œæ•°æ®                                                   | äº’è”ç½‘ä¸Šå…¬å¼€çš„ç½‘ç»œæ•°æ®ï¼ŒæŒ‘é€‰å‡ºå»é‡åçš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼Œæ¶‰åŠåˆ°ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ç­‰é«˜è´¨é‡é•¿æ–‡æœ¬æ•°æ®ã€‚ |
| [Wikipedia](https://github.com/goldsmith/Wikipedia)        | ä¸­æ–‡Wikipediaçš„æ•°æ®                                          |
| [æ‚Ÿé“](https://github.com/BAAI-WuDao/Model)                | ä¸­æ–‡æ‚Ÿé“å¼€æºçš„200Gæ•°æ®                                       |
| [Clue](https://github.com/CLUEbenchmark/CLUEDatasetSearch) | Clueå¼€æ”¾çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—åçš„é«˜è´¨é‡ä¸­æ–‡é•¿æ–‡æœ¬æ•°æ®   |
| ç«èµ›æ•°æ®é›†                                                 | è¿‘å¹´æ¥ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å¤šä»»åŠ¡ç«èµ›æ•°æ®é›†ï¼Œçº¦150ä¸ª              |
| [MNBVC](https://github.com/esbatmop/MNBVC)                 | MNBVC ä¸­æ¸…æ´—å‡ºæ¥çš„éƒ¨åˆ†æ•°æ®é›†

ç¤¾åŒºæä¾›é¢„è®­ç»ƒç‰ˆæœ¬Atom-7Bå’ŒåŸºäºAtom-7Bè¿›è¡Œå¯¹è¯å¾®è°ƒçš„æ¨¡å‹å‚æ•°ä¾›å¼€æ”¾ä¸‹è½½ï¼Œå…³äºæ¨¡å‹çš„è¿›å±•è¯¦è§ç¤¾åŒºå®˜ç½‘[llama.family](https://llama.family)ã€‚

#### Llama3å®˜æ–¹æ¨¡å‹

|  ç±»åˆ«  | æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
|  ----------  | ---------- | ------------------------- | --------------------- |
|  é¢„è®­ç»ƒ  | Llama3-8B  | meta-llama/Meta-Llama-3-8B  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-8B) \| [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq) |
|  é¢„è®­ç»ƒ  | Llama3-70B | meta-llama/Meta-Llama-3-70B | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-7B) \| [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq) |
|  å¯¹è¯æ¨¡å‹  | Llama3-8B-Chat  | meta-llama/Meta-Llama-3-8B-Instruct  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) \| [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq) |
|  å¯¹è¯æ¨¡å‹  | Llama3-70B-Chat  | meta-llama/Meta-Llama-3-70B-Instruct  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) \| [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq) |

#### Llama3ä¸­æ–‡å¾®è°ƒæ¨¡å‹

|  ç±»åˆ«  | æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
|  ----------  | ---------- | ------------------------- | --------------------- |
|  å¯¹è¯æ¨¡å‹  | Llama3-Chinese-8B-Instruct  | FlagAlpha/Llama3-Chinese-8B-Instruct  | [HuggingFace](https://huggingface.co/FlagAlpha/Llama3-Chinese-8B-Instruct) \| [modelscope](https://modelscope.cn/models/FlagAlpha/Llama3-Chinese-8B-Instruct/summary) \| [wisemodel](https://wisemodel.cn/models/FlagAlpha/Llama3-Chinese-8B-Instruct/file) |


#### Llama2å®˜æ–¹æ¨¡å‹

<details>

|  ç±»åˆ«  | æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
|  ----------  | ---------- | ------------------------- | --------------------- |
|  é¢„è®­ç»ƒ  | Llama2-7B  | meta-llama/Llama-2-7b-hf  | [HuggingFace](https://huggingface.co/meta-llama/Llama-2-7b-hf) \| [è¿…é›·ç½‘ç›˜](https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep) |
|  é¢„è®­ç»ƒ  | Llama2-13B | meta-llama/Llama-2-13b-hf | [HuggingFace](https://huggingface.co/meta-llama/Llama-2-13b-hf) \| [è¿…é›·ç½‘ç›˜](https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf) |
|  é¢„è®­ç»ƒ  | Llama2-70B | meta-llama/Llama-2-70b-hf | [HuggingFace](https://huggingface.co/meta-llama/Llama-2-70b-hf) |
|  Chat  | Llama2-7B-Chat  | meta-llama/Llama-2-7b-chat-hf  | [HuggingFace](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) \| [è¿…é›·ç½‘ç›˜](https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir) |
|  Chat  | Llama2-13B-Chat | meta-llama/Llama-2-13b-chat-hf | [HuggingFace](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf) \| [è¿…é›·ç½‘ç›˜](https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg) |
|  Chat  | Llama2-70B-Chat | meta-llama/Llama-2-70b-chat-hf | [HuggingFace](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf) \| [è¿…é›·ç½‘ç›˜](https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#) |
| Code  | CodeLlama-7b    |   meta-llama/Llama-2-70b-chat-hf              | [è¿…é›·ç½‘ç›˜](https://pan.baidu.com/s/1cIPzdNywWLvQI7_2QanOEQ?pwd=zfwi) |
| Code  | CodeLlama-7b-Python    |   meta-llama/Llama-2-70b-chat-hf              | [è¿…é›·ç½‘ç›˜](https://pan.baidu.com/s/1liY8klGoDagYbpw-g-oFag?pwd=i952) |
| Code  | CodeLlama-7b-Instruct    |   meta-llama/Llama-2-70b-chat-hf              | [è¿…é›·ç½‘ç›˜](https://pan.baidu.com/s/108o9_DT2E_vfSGtOnDCQVw?pwd=zkt9) |
| Code  | CodeLlama-13b    |   meta-llama/Llama-2-70b-chat-hf              | [è¿…é›·ç½‘ç›˜](https://pan.baidu.com/s/1lLaeHv0XEBv0iiZzI1dpnw?pwd=qn99) |
| Code  | CodeLlama-13b-Python    |   meta-llama/Llama-2-70b-chat-hf              | [è¿…é›·ç½‘ç›˜](https://pan.baidu.com/s/1OLVfvZS_oqL3oqMKwsI87w?pwd=a78k) |
| Code  | CodeLlama-13b-Instruct    |   meta-llama/Llama-2-70b-chat-hf              | [è¿…é›·ç½‘ç›˜](https://pan.baidu.com/s/1HyxJl4w8wElgkZRh2ATrXQ?pwd=seg6) |
| Code  | CodeLlama-34b    |   meta-llama/Llama-2-70b-chat-hf              | [è¿…é›·ç½‘ç›˜](https://pan.baidu.com/s/1vEw0pFgIkctPUN4_5_6pIQ?pwd=q8eu) |

Metaå®˜æ–¹åœ¨2023å¹´8æœˆ24æ—¥å‘å¸ƒäº†Code Llamaï¼ŒåŸºäºä»£ç æ•°æ®å¯¹Llama2è¿›è¡Œäº†å¾®è°ƒï¼Œæä¾›ä¸‰ä¸ªä¸åŒåŠŸèƒ½çš„ç‰ˆæœ¬ï¼šåŸºç¡€æ¨¡å‹ï¼ˆCode Llamaï¼‰ã€Pythonä¸“ç”¨æ¨¡å‹ï¼ˆCode Llama - Pythonï¼‰å’ŒæŒ‡ä»¤è·Ÿéšæ¨¡å‹ï¼ˆCode Llama - Instructï¼‰ï¼ŒåŒ…å«7Bã€13Bã€34Bä¸‰ç§ä¸åŒå‚æ•°è§„æ¨¡ã€‚ä¸åŒæ¨¡å‹èƒ½åŠ›åŒºåˆ«å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š

|  æ¨¡å‹ç±»åˆ«          |        æ¨¡å‹åç§°         | ä»£ç ç»­å†™ | ä»£ç å¡«å…… | æŒ‡ä»¤ç¼–ç¨‹ |
|-----------------------|------------------------|------|------|------|
| Code Llama            | CodeLlama-7b           | âœ…    | âœ…    | âŒ    |
|                       | CodeLlama-13b          | âœ…    | âœ…    | âŒ    |
|                       | CodeLlama-34b          | âœ…    | âŒ    | âŒ    |
| Code Llama - Python   | CodeLlama-7b-Python    | âœ…    | âŒ    | âŒ    |
|                       | CodeLlama-13b-Python   | âœ…    | âŒ    | âŒ    |
|                       | CodeLlama-34b-Python   | âœ…    | âŒ    | âŒ    |
| Code Llama - Instruct | CodeLlama-7b-Instruct  | âŒ    | âœ…    | âœ…    |
|                       | CodeLlama-13b-Instruct | âŒ    | âœ…    | âœ…    |
|                       | CodeLlama-34b-Instruct | âŒ    | âŒ    | âœ…    |

å…³äºCode Llamaçš„è¯¦ç»†ä¿¡æ¯å¯ä»¥å‚è€ƒå®˜æ–¹Githubä»“åº“[codellama](https://github.com/facebookresearch/codellama)ã€‚

</details>

#### Llama2ä¸­æ–‡å¾®è°ƒæ¨¡å‹

æˆ‘ä»¬åŸºäºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†å¯¹Llama2-Chatæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿å¾—Llama2æ¨¡å‹æœ‰ç€æ›´å¼ºçš„ä¸­æ–‡å¯¹è¯èƒ½åŠ›ã€‚LoRAå‚æ•°ä»¥åŠä¸åŸºç¡€æ¨¡å‹åˆå¹¶çš„å‚æ•°å‡å·²ä¸Šä¼ è‡³[Hugging Face](https://huggingface.co/FlagAlpha)ï¼Œç›®å‰åŒ…å«7Bå’Œ13Bçš„æ¨¡å‹ã€‚

|  ç±»åˆ«  | æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | åŸºç¡€æ¨¡å‹ç‰ˆæœ¬ |    ä¸‹è½½åœ°å€                                                     |
|  ----------  | ---------- | ------------- |  ----------------- | ------------------- |
|  åˆå¹¶å‚æ•° | Llama2-Chinese-7b-Chat | FlagAlpha/Llama2-Chinese-7b-Chat  |    meta-llama/Llama-2-7b-chat-hf       |[HuggingFace](https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat)  |
|  åˆå¹¶å‚æ•° | Llama2-Chinese-13b-Chat | FlagAlpha/Llama2-Chinese-13b-Chat|     meta-llama/Llama-2-13b-chat-hf     |[HuggingFace](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat) |
|  LoRAå‚æ•° | Llama2-Chinese-7b-Chat-LoRA  | FlagAlpha/Llama2-Chinese-7b-Chat-LoRA  |     meta-llama/Llama-2-7b-chat-hf      |[HuggingFace](https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat-LoRA) |
|  LoRAå‚æ•° | Llama2-Chinese-13b-Chat-LoRA | FlagAlpha/Llama2-Chinese-13b-Chat-LoRA |     meta-llama/Llama-2-13b-chat-hf     |[HuggingFace](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA) |


### ç¤¾åŒºèµ„æº
ç¤¾åŒºèµ„æºçš„ä¸°å¯Œæ€§æ˜¯ç¤¾åŒºå‘å±•çš„é‡è¦ä¿éšœï¼Œå®ƒæ¶µç›–äº†å„ç§æ–¹é¢ï¼Œå…¶ä¸­åŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹å››ä¸ªæ–¹é¢ï¼šç®—åŠ›ã€æ•°æ®ã€è®ºå›å’Œåº”ç”¨ã€‚åœ¨è¿™äº›æ–¹é¢çš„ç§¯æå‘å±•ä¸å……åˆ†åˆ©ç”¨ï¼Œå°†ä¸ºç¤¾åŒºæˆå‘˜æä¾›æ›´å¤šçš„æœºä¼šå’Œæ”¯æŒï¼Œæ¨åŠ¨æ•´ä¸ªç¤¾åŒºå‘ç€æ›´åŠ ç¹è£çš„æ–¹å‘å‘å±•ã€‚æ›´å¤šçš„å†…å®¹è¯·çœ‹[llama.family](https://llama.family/)

<details>

#### ğŸ’» ç®—åŠ›
- æä¾›ä½äºå¸‚åœºä»·æ ¼çš„ç®—åŠ›èµ„æºï¼Œå¯ç”¨äºå„ç±»è®¡ç®—ä»»åŠ¡ï¼Œå¦‚æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒã€æ¨ç†ç­‰ã€‚
- ä¸ºç¤¾åŒºæˆå‘˜æä¾›ä¸“å±çš„åœ¨çº¿æ¨ç†æœåŠ¡ï¼Œè®©ç”¨æˆ·å¯ä»¥å¿«é€Ÿæœ‰æ•ˆåœ°å¯¹æ¨¡å‹è¿›è¡Œæ¨ç†æ“ä½œã€‚
- æä¾›ä¸€é”®åœ¨çº¿å¾®è°ƒæœåŠ¡ï¼Œä½¿ç”¨æˆ·å¯ä»¥æ–¹ä¾¿åœ°å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œæ•°æ®ã€‚

#### ğŸ“Š æ•°æ®
- å¼€æ”¾ä¸°å¯Œçš„è®­ç»ƒæ•°æ®èµ„æºï¼Œè¦†ç›–å¤šä¸ªé¢†åŸŸå’Œè¡Œä¸šï¼Œä¸ºæ¨¡å‹è®­ç»ƒæä¾›å……è¶³çš„æ•°æ®æ”¯æŒã€‚
- æä¾›é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œä»¥æ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ï¼Œå¹¶æ”¯æŒæ•°æ®å…±äº«å’Œäº¤æµï¼Œä¿ƒè¿›æ•°æ®èµ„æºçš„å……åˆ†åˆ©ç”¨ã€‚

#### ğŸ’¬ è®ºå›
- ç¤¾åŒºè®ºå›ä¸ºç¤¾åŒºæˆå‘˜æä¾›äº†ä¸€ä¸ªåœ¨çº¿äº¤æµå’Œè®¨è®ºæŠ€æœ¯é—®é¢˜çš„å¹³å°ã€‚
- åœ¨è®ºå›ä¸Šï¼Œç”¨æˆ·å¯ä»¥åˆ†äº«ç»éªŒã€æå‡ºé—®é¢˜ã€è§£ç­”ç–‘æƒ‘ï¼Œä¿ƒè¿›æŠ€æœ¯äº¤æµå’Œåˆä½œã€‚
- è®ºå›è¿˜å¯ä»¥å®šæœŸä¸¾åŠçº¿ä¸Šæ´»åŠ¨ã€ç ”è®¨ä¼šç­‰ï¼Œå¢è¿›ç¤¾åŒºæˆå‘˜ä¹‹é—´çš„è”ç³»å’Œäº†è§£ã€‚

#### ğŸ“± åº”ç”¨
- å…è´¹æä¾›åº”ç”¨æ¨å¹¿å±•ç¤ºä½ï¼Œè®©å¼€å‘è€…å¯ä»¥å°†ä»–ä»¬çš„åº”ç”¨å……åˆ†å±•ç¤ºç»™ç¤¾åŒºæˆå‘˜ã€‚
- æä¾›æ¨å¹¿çš„å¸®åŠ©ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå®£ä¼ æ¨å¹¿ã€ç”¨æˆ·å¼•å¯¼ç­‰æœåŠ¡ï¼Œå¸®åŠ©åº”ç”¨è·å¾—æ›´å¤šçš„æ›å…‰å’Œç”¨æˆ·ã€‚
- é€šè¿‡ç¤¾åŒºå¹³å°ï¼Œä¸ºä¼˜ç§€çš„åº”ç”¨æä¾›åˆä½œæœºä¼šï¼Œä¿ƒè¿›åº”ç”¨å¼€å‘è€…ä¹‹é—´çš„åˆä½œå’Œäº¤æµï¼Œå…±åŒæ¨åŠ¨åº”ç”¨çš„å‘å±•å’Œå£®å¤§ã€‚

</details>

## ğŸ“Œ å¦‚ä½•ä½¿ç”¨Llamaæ¨¡å‹?


ä½ å¯ä»¥é€‰æ‹©ä¸‹é¢çš„å¿«é€Ÿä¸Šæ‰‹çš„ä»»ä¸€ç§æ–¹å¼ï¼Œå¼€å§‹ä½¿ç”¨ Llama ç³»åˆ—æ¨¡å‹ã€‚æ¨èä½¿ç”¨[ä¸­æ–‡é¢„è®­ç»ƒå¯¹è¯æ¨¡å‹](#llama2ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹atom-7b)è¿›è¡Œä½¿ç”¨ï¼Œå¯¹ä¸­æ–‡çš„æ•ˆæœæ”¯æŒæ›´å¥½ã€‚


### å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Anaconda

ç¬¬ 0 æ­¥ï¼šå‰ææ¡ä»¶
- ç¡®ä¿å®‰è£…äº† Python 3.10 ä»¥ä¸Šç‰ˆæœ¬ã€‚

ç¬¬ 1 æ­¥ï¼šå‡†å¤‡ç¯å¢ƒ

å¦‚éœ€è®¾ç½®ç¯å¢ƒï¼Œå®‰è£…æ‰€éœ€è¦çš„è½¯ä»¶åŒ…ï¼Œè¿è¡Œä¸‹é¢çš„å‘½ä»¤ã€‚
```bash
git clone https://github.com/LlamaFamily/Llama-Chinese.git
cd Llama-Chinese
pip install -r requirements.txt
```

ç¬¬ 2 æ­¥ï¼šä¸‹è½½æ¨¡å‹

ä½ å¯ä»¥ä»ä»¥ä¸‹æ¥æºä¸‹è½½Atom-7B-Chatæ¨¡å‹ã€‚
- [HuggingFace](https://huggingface.co/FlagAlpha)
- [ModelScope](https://modelscope.cn/organization/FlagAlpha)
- [WiseModel](https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat)

ç¬¬ 3 æ­¥ï¼šè¿›è¡Œæ¨ç†

ä½¿ç”¨Atom-7B-Chatæ¨¡å‹è¿›è¡Œæ¨ç†
åˆ›å»ºä¸€ä¸ªåä¸º quick_start.py çš„æ–‡ä»¶ï¼Œå¹¶å°†ä»¥ä¸‹å†…å®¹å¤åˆ¶åˆ°è¯¥æ–‡ä»¶ä¸­ã€‚
```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
device_map = "cuda:0" if torch.cuda.is_available() else "auto"
model = AutoModelForCausalLM.from_pretrained('FlagAlpha/Atom-7B-Chat',device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)
model =model.eval()
tokenizer = AutoTokenizer.from_pretrained('FlagAlpha/Atom-7B-Chat',use_fast=False)
tokenizer.pad_token = tokenizer.eos_token
input_ids = tokenizer(['<s>Human: ä»‹ç»ä¸€ä¸‹ä¸­å›½\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids
if torch.cuda.is_available():
  input_ids = input_ids.to('cuda')
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```

è¿è¡Œ quick_start.py ä»£ç ã€‚
```bash
python quick_start.py
```

### å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Docker

è¯¦æƒ…å‚è§ï¼š[Dockeréƒ¨ç½²](https://github.com/LlamaFamily/Llama-Chinese/blob/main/docs/chat_gradio_guide.md)

ç¬¬ 1 æ­¥ï¼šå‡†å¤‡dockeré•œåƒï¼Œé€šè¿‡dockerå®¹å™¨å¯åŠ¨[chat_gradio.py](../examples/chat_gradio.py)
```bash
git clone https://github.com/LlamaFamily/Llama-Chinese.git

cd Llama-Chinese

docker build -f docker/Dockerfile -t flagalpha/llama2-chinese:gradio .
```

ç¬¬ 2 æ­¥ï¼šé€šè¿‡docker-composeå¯åŠ¨chat_gradio
```bash
cd Llama-Chinese/docker
docker-compose up -d --build
```

### å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨llama.cpp
è¯¦æƒ…å‚è§ï¼š[ä½¿ç”¨llama.cpp](https://github.com/LlamaFamily/Llama-Chinese/blob/main/inference-speed/CPU/ggml/README.md)

### å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨gradio
åŸºäºgradioæ­å»ºçš„é—®ç­”ç•Œé¢ï¼Œå®ç°äº†æµå¼çš„è¾“å‡ºï¼Œå°†ä¸‹é¢ä»£ç å¤åˆ¶åˆ°æ§åˆ¶å°è¿è¡Œï¼Œä»¥ä¸‹ä»£ç ä»¥Atom-7B-Chatæ¨¡å‹ä¸ºä¾‹ï¼Œä¸åŒæ¨¡å‹åªéœ€ä¿®æ”¹ä¸€ä¸‹é¢çš„model_name_or_pathå¯¹åº”çš„æ¨¡å‹åç§°å°±å¥½äº†ğŸ˜Š
```
python examples/chat_gradio.py --model_name_or_path FlagAlpha/Atom-7B-Chat
```

### å¿«é€Ÿä¸Šæ‰‹-æ„å»ºAPIæœåŠ¡
ä½¿ç”¨FastChatæ„å»ºå’ŒOpenAIä¸€è‡´çš„æ¨ç†æœåŠ¡æ¥å£ã€‚

<details>
ç¬¬ 0 æ­¥ï¼šå‰ææ¡ä»¶

å®‰è£…fastchat
```bash
pip3 install "fschat[model_worker,webui]"
```
ç¬¬ 1 æ­¥ï¼šå¯åŠ¨Restful API

å¼€å¯ä¸‰ä¸ªæ§åˆ¶å°åˆ†åˆ«æ‰§è¡Œä¸‹é¢çš„ä¸‰ä¸ªå‘½ä»¤
- é¦–å…ˆå¯åŠ¨controler
```bash
python3 -m fastchat.serve.controller \
--host localhost \
--port 21001
```

- å¯åŠ¨æ¨¡å‹
```bash
CUDA_VISIBLE_DEVICES="0" python3 -m fastchat.serve.model_worker --model-path /path/Atom-7B-Chat \
--host localhost \
--port 21002 \
--worker-address "http://localhost:21002" \
--limit-worker-concurrency 5 \
--stream-interval 2 \
--gpus "1" \
--load-8bit
```

- å¯åŠ¨RESTful API æœåŠ¡
```bash
python3 -m fastchat.serve.openai_api_server \
--host localhost \
--port 21003 \
--controller-address http://localhost:21001
```

ç¬¬ 2 æ­¥ï¼šæµ‹è¯•apiæœåŠ¡

æ‰§è¡Œä¸‹é¢çš„pythonä»£ç æµ‹è¯•ä¸Šé¢éƒ¨ç½²çš„apiæœåŠ¡
```python
# coding=utf-8
import json
import time
import urllib.request
import sys
import requests

def test_api_server(input_text):
    header = {'Content-Type': 'application/json'}

    data = {
          "messages": [{"role": "system", "content": ""}, {"role": "user", "content": input_text}],
          "temperature": 0.3, 
          "top_p" : 0.95, 
          "max_tokens": 512, 
          "model": "LLama2-Chinese-13B",
          "stream" : False,
          "n" : 1,
          "best_of": 1, 
          "presence_penalty": 1.2, 
          "frequency_penalty": 0.2,           
          "top_k": 50, 
          "use_beam_search": False, 
          "stop": [], 
          "ignore_eos" :False,
          "logprobs": None
    }
    response = requests.post(
        url='http://127.0.0.1:21003/v1/chat/completions',
        headers=header,
        data=json.dumps(data).encode('utf-8')
    )

    result = None
    try:
        result = json.loads(response.content)
        print(json.dumps(data, ensure_ascii=False, indent=2))
        print(json.dumps(result, ensure_ascii=False, indent=2))

    except Exception as e:
        print(e)

    return result

if __name__ == "__main__":
    test_api_server("å¦‚ä½•å»åŒ—äº¬?")
```

</details>


### å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨ollamaè¿è¡Œ

1. é¦–å…ˆéœ€è¦å®‰è£…ollamaå·¥å…·

å®‰è£…æ–¹æ³•å‚è€ƒï¼š[https://ollama.com](https://ollama.com/)

2. ollamaè¿è¡ŒLlama3-Chinese-8B-Instructã€Atom-7B-Chat

ollamaè¿è¡ŒåŸºäºLlama3è¿›è¡Œä¸­æ–‡å¾®è°ƒçš„å¤§æ¨¡å‹[Llama3-Chinese-8B-Instruct](https://huggingface.co/FlagAlpha/Llama3-Chinese-8B-Instruct)

æ‰“å¼€å‘½ä»¤è¡Œæ‰§è¡Œå‘½ä»¤
```
ollama run llamafamily/llama3-chinese-8b-instruct
```

ollamaè¿è¡ŒåŸºäºLlama2è¿›è¡Œä¸­æ–‡é¢„è®­ç»ƒçš„å¼€æºå¤§æ¨¡å‹[Atom-7B-Chat](https://huggingface.co/FlagAlpha/Atom-7B-Chat)

æ‰“å¼€å‘½ä»¤è¡Œæ‰§è¡Œå‘½ä»¤
```
ollama run llamafamily/atom-7b-chat
```


## ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ
è™½ç„¶Llama2çš„é¢„è®­ç»ƒæ•°æ®ç›¸å¯¹äºç¬¬ä¸€ä»£LLaMAæ‰©å¤§äº†ä¸€å€ï¼Œä½†æ˜¯ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®çš„æ¯”ä¾‹ä¾ç„¶éå¸¸å°‘ï¼Œä»…å 0.13%ï¼Œè¿™ä¹Ÿå¯¼è‡´äº†åŸå§‹Llama2çš„ä¸­æ–‡èƒ½åŠ›è¾ƒå¼±ã€‚ä¸ºäº†èƒ½å¤Ÿæå‡æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›ï¼Œå¯ä»¥é‡‡ç”¨å¾®è°ƒå’Œé¢„è®­ç»ƒä¸¤ç§è·¯å¾„ï¼Œå…¶ä¸­ï¼š
- å¾®è°ƒéœ€è¦çš„ç®—åŠ›èµ„æºå°‘ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®ç°ä¸€ä¸ªä¸­æ–‡Llamaçš„é›å½¢ã€‚ä½†ç¼ºç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œåªèƒ½æ¿€å‘åŸºåº§æ¨¡å‹å·²æœ‰çš„ä¸­æ–‡èƒ½åŠ›ï¼Œç”±äºLlama2çš„ä¸­æ–‡è®­ç»ƒæ•°æ®æœ¬èº«è¾ƒå°‘ï¼Œæ‰€ä»¥èƒ½å¤Ÿæ¿€å‘çš„èƒ½åŠ›ä¹Ÿæœ‰é™ï¼Œæ²»æ ‡ä¸æ²»æœ¬ã€‚

- åŸºäºå¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™è¿›è¡Œé¢„è®­ç»ƒï¼Œæˆæœ¬é«˜ï¼Œä¸ä»…éœ€è¦å¤§è§„æ¨¡é«˜è´¨é‡çš„ä¸­æ–‡æ•°æ®ï¼Œä¹Ÿéœ€è¦å¤§è§„æ¨¡çš„ç®—åŠ›èµ„æºã€‚ä½†æ˜¯ä¼˜ç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œå°±æ˜¯èƒ½ä»æ¨¡å‹åº•å±‚ä¼˜åŒ–ä¸­æ–‡èƒ½åŠ›ï¼ŒçœŸæ­£è¾¾åˆ°æ²»æœ¬çš„æ•ˆæœï¼Œä»å†…æ ¸ä¸ºå¤§æ¨¡å‹æ³¨å…¥å¼ºå¤§çš„ä¸­æ–‡èƒ½åŠ›ã€‚

æˆ‘ä»¬ä¸ºç¤¾åŒºæä¾›äº†Llamaæ¨¡å‹çš„é¢„è®­ç»ƒä»£ç ï¼Œä»¥åŠ[ä¸­æ–‡æµ‹è¯•è¯­æ–™](https://github.com/LlamaFamily/Llama-Chinese/tree/main/data)ï¼Œæ›´å¤šæ•°æ®å¯ä»¥å‚è€ƒ[ä¸­æ–‡è¯­æ–™](#-ä¸­æ–‡æ•°æ®)ã€‚å…·ä½“ä»£ç å’Œé…ç½®å¦‚ä¸‹ï¼š
- æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼š[train/pretrain/pretrain.sh](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/pretrain/pretrain.sh)
- é¢„è®­ç»ƒå®ç°ä»£ç ï¼š[train/pretrain/pretrain_clm.py](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/pretrain/pretrain_clm.py)
- [DeepSpeed](https://github.com/microsoft/DeepSpeed)åŠ é€Ÿï¼š
  - å¯¹äºå•å¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-2çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ [train/pretrain/ds_config_zero2.json](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/pretrain/ds_config_zero2.json)
  - å¯¹äºå¤šå¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-3çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ [train/pretrain/ds_config_zero3.json](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/pretrain/ds_config_zero3.json)
- è®­ç»ƒæ•ˆæœåº¦é‡æŒ‡æ ‡ï¼š[train/pretrain/accuracy.py](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/pretrain/accuracy.py)

## ğŸ’¡ æ¨¡å‹å¾®è°ƒ

æœ¬ä»“åº“ä¸­åŒæ—¶æä¾›äº†LoRAå¾®è°ƒå’Œå…¨é‡å‚æ•°å¾®è°ƒä»£ç ï¼Œå…³äºLoRAçš„è¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒè®ºæ–‡â€œ[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)â€ä»¥åŠå¾®è½¯Githubä»“åº“[LoRA](https://github.com/microsoft/LoRA)ã€‚

### Step1: ç¯å¢ƒå‡†å¤‡

æ ¹æ®[requirements.txt](https://github.com/LlamaFamily/Llama-Chinese/blob/main/requirements.txt)å®‰è£…å¯¹åº”çš„ç¯å¢ƒä¾èµ–ã€‚

### Step2: æ•°æ®å‡†å¤‡
åœ¨dataç›®å½•ä¸‹æä¾›äº†ä¸€ä»½ç”¨äºæ¨¡å‹sftçš„æ•°æ®æ ·ä¾‹ï¼š
- è®­ç»ƒæ•°æ®ï¼š[data/train_sft.csv](https://github.com/LlamaFamily/Llama-Chinese/blob/main/data/train_sft.csv)
- éªŒè¯æ•°æ®ï¼š[data/dev_sft.csv](https://github.com/LlamaFamily/Llama-Chinese/blob/main/data/dev_sft.csv)

æ¯ä¸ªcsvæ–‡ä»¶ä¸­åŒ…å«ä¸€åˆ—â€œtextâ€ï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªè®­ç»ƒæ ·ä¾‹ï¼Œæ¯ä¸ªè®­ç»ƒæ ·ä¾‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å°†é—®é¢˜å’Œç­”æ¡ˆç»„ç»‡ä¸ºæ¨¡å‹è¾“å…¥ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è‡ªå®šä¹‰è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ï¼š
```
"<s>Human: "+é—®é¢˜+"\n</s><s>Assistant: "+ç­”æ¡ˆ+"\n"</s>
```
ä¾‹å¦‚ï¼Œ
```
<s>Human: ç”¨ä¸€å¥è¯æè¿°åœ°çƒä¸ºä»€ä¹ˆæ˜¯ç‹¬ä¸€æ— äºŒçš„ã€‚</s><s>Assistant: å› ä¸ºåœ°çƒæ˜¯ç›®å‰ä¸ºæ­¢å”¯ä¸€å·²çŸ¥å­˜åœ¨ç”Ÿå‘½çš„è¡Œæ˜Ÿã€‚</s>
```

### Step3: å¾®è°ƒè„šæœ¬

#### LoRAå¾®è°ƒ
LoRAå¾®è°ƒè„šæœ¬è§ï¼š[train/sft/finetune_lora.sh](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/sft/finetune_lora.sh)ï¼Œå…³äºLoRAå¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§[train/sft/finetune_clm_lora.py](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/sft/finetune_clm_lora.py)ï¼Œå•æœºå¤šå¡çš„å¾®è°ƒå¯ä»¥é€šè¿‡ä¿®æ”¹è„šæœ¬ä¸­çš„`--include localhost:0`æ¥å®ç°ã€‚

#### å…¨é‡å‚æ•°å¾®è°ƒ
å…¨é‡å‚æ•°å¾®è°ƒè„šæœ¬è§ï¼š[train/sft/finetune.sh](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/sft/finetune.sh)ï¼Œå…³äºå…¨é‡å‚æ•°å¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§[train/sft/finetune_clm.py](https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/sft/finetune_clm.py)ã€‚


### Step4: åŠ è½½å¾®è°ƒæ¨¡å‹

#### LoRAå¾®è°ƒ
åŸºäºLoRAå¾®è°ƒçš„æ¨¡å‹å‚æ•°è§ï¼š[åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹](#llama2ä¸­æ–‡å¾®è°ƒæ¨¡å‹)ï¼ŒLoRAå‚æ•°éœ€è¦å’ŒåŸºç¡€æ¨¡å‹å‚æ•°ç»“åˆä½¿ç”¨ã€‚

é€šè¿‡[PEFT](https://github.com/huggingface/peft)åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å‚æ•°å’Œå¾®è°ƒæ¨¡å‹å‚æ•°ï¼Œä»¥ä¸‹ç¤ºä¾‹ä»£ç ä¸­ï¼Œbase_model_name_or_pathä¸ºé¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ï¼Œfinetune_model_pathä¸ºå¾®è°ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ã€‚

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel,PeftConfig
# ä¾‹å¦‚: finetune_model_path='FlagAlpha/Llama2-Chinese-7b-Chat-LoRA'
finetune_model_path=''  
config = PeftConfig.from_pretrained(finetune_model_path)
# ä¾‹å¦‚: base_model_name_or_path='meta-llama/Llama-2-7b-chat'
tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,use_fast=False)
tokenizer.pad_token = tokenizer.eos_token
device_map = "cuda:0" if torch.cuda.is_available() else "auto"
model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)
model = PeftModel.from_pretrained(model, finetune_model_path, device_map={"": 0})
model =model.eval()
input_ids = tokenizer(['<s>Human: ä»‹ç»ä¸€ä¸‹åŒ—äº¬\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids
if torch.cuda.is_available():
  input_ids = input_ids.to('cuda')
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```

#### å…¨é‡å‚æ•°å¾®è°ƒ
å¯¹äºå…¨é‡å‚æ•°å¾®è°ƒçš„æ¨¡å‹ï¼Œè°ƒç”¨æ–¹å¼åŒ[æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹](#æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹)ï¼Œåªéœ€è¦ä¿®æ”¹å…¶ä¸­çš„æ¨¡å‹åç§°æˆ–è€…ä¿å­˜è·¯å¾„å³å¯ã€‚

## ğŸ„ æ¨¡å‹é‡åŒ–
æˆ‘ä»¬å¯¹ä¸­æ–‡å¾®è°ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œäº†é‡åŒ–ï¼Œæ–¹ä¾¿ä»¥æ›´å°‘çš„è®¡ç®—èµ„æºè¿è¡Œã€‚ç›®å‰å·²ç»åœ¨[Hugging Face](https://huggingface.co/FlagAlpha)ä¸Šä¼ äº†13Bä¸­æ–‡å¾®è°ƒæ¨¡å‹[FlagAlpha/Llama2-Chinese-13b-Chat](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat)çš„4bitå‹ç¼©ç‰ˆæœ¬[FlagAlpha/Llama2-Chinese-13b-Chat-4bit](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit)ï¼Œå…·ä½“è°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š

ç¯å¢ƒå‡†å¤‡ï¼š
```
pip install git+https://github.com/PanQiWei/AutoGPTQ.git
```

```python
from transformers import AutoTokenizer
from auto_gptq import AutoGPTQForCausalLM
model = AutoGPTQForCausalLM.from_quantized('FlagAlpha/Llama2-Chinese-13b-Chat-4bit', device="cuda:0")
tokenizer = AutoTokenizer.from_pretrained('FlagAlpha/Llama2-Chinese-13b-Chat-4bit',use_fast=False)
input_ids = tokenizer(['<s>Human: æ€ä¹ˆç™»ä¸Šç«æ˜Ÿ\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids.to('cuda')        
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```

## ğŸš€ éƒ¨ç½²åŠ é€Ÿ
éšç€å¤§æ¨¡å‹å‚æ•°è§„æ¨¡çš„ä¸æ–­å¢é•¿ï¼Œåœ¨æœ‰é™çš„ç®—åŠ›èµ„æºä¸‹ï¼Œæå‡æ¨¡å‹çš„æ¨ç†é€Ÿåº¦é€æ¸å˜ä¸ºä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚å¸¸ç”¨çš„æ¨ç†åŠ é€Ÿæ¡†æ¶åŒ…å« lmdeployã€TensorRT-LLMã€vLLMå’ŒJittorLLMs ç­‰ã€‚

### TensorRT-LLM
[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM/tree/main)ç”±NVIDIAå¼€å‘ï¼Œé«˜æ€§èƒ½æ¨ç†æ¡†æ¶

è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š[inference-speed/GPU/TensorRT-LLM_example](https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/TensorRT-LLM_example)

### vLLM
[vLLM](https://github.com/vllm-project/vllm)ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å¼€å‘ï¼Œæ ¸å¿ƒæŠ€æœ¯æ˜¯PageAttentionï¼Œååé‡æ¯”HuggingFace Transformersé«˜å‡º24å€ã€‚ç›¸è¾ƒä¸FasterTrainsformerï¼ŒvLLMæ›´åŠ çš„ç®€å•æ˜“ç”¨ï¼Œä¸éœ€è¦é¢å¤–è¿›è¡Œæ¨¡å‹çš„è½¬æ¢ï¼Œæ”¯æŒfp16æ¨ç†ã€‚

è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š[inference-speed/GPU/vllm_example](https://github.com/LlamaFamily/Llama-Chinese/blob/main/inference-speed/GPU/vllm_example/README.md)

### JittorLLMs
[JittorLLMs](https://github.com/Jittor/JittorLLMs)ç”±éåç§‘æŠ€é¢†è¡”ï¼Œä¸æ¸…åå¤§å­¦å¯è§†åª’ä½“ç ”ç©¶ä¸­å¿ƒåˆä½œç ”å‘ï¼Œé€šè¿‡åŠ¨æ€swapæœºåˆ¶å¤§å¹…é™ä½ç¡¬ä»¶é…ç½®è¦æ±‚ï¼ˆå‡å°‘80%ï¼‰,å¹¶ä¸”Jittoræ¡†æ¶é€šè¿‡é›¶æ‹·è´æŠ€æœ¯ï¼Œå¤§æ¨¡å‹åŠ è½½ç›¸æ¯”Pytorchå¼€é”€é™ä½40%ï¼ŒåŒæ—¶ï¼Œé€šè¿‡å…ƒç®—å­è‡ªåŠ¨ç¼–è¯‘ä¼˜åŒ–ï¼Œè®¡ç®—æ€§èƒ½æå‡20%ä»¥ä¸Šã€‚

è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š[inference-speed/GPU/JittorLLMs](https://github.com/LlamaFamily/Llama-Chinese/blob/main/inference-speed/GPU/JittorLLMs_example/README.md)

### lmdeploy
[lmdeploy](https://github.com/InternLM/lmdeploy/) ç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€å‘ï¼Œæ¨ç†ä½¿ç”¨ C++/CUDAï¼Œå¯¹å¤–æä¾› python/gRPC/http æ¥å£å’Œ WebUI ç•Œé¢ï¼Œæ”¯æŒ tensor parallel åˆ†å¸ƒå¼æ¨ç†ã€æ”¯æŒ fp16/weight int4/kv cache int8 é‡åŒ–ã€‚

è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š[inference-speed/GPU/lmdeploy_example](https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/lmdeploy_example)

## ğŸ’ª å¤–å»¶èƒ½åŠ›

é™¤äº†æŒç»­å¢å¼ºå¤§æ¨¡å‹å†…åœ¨çš„çŸ¥è¯†å‚¨å¤‡ã€é€šç”¨ç†è§£ã€é€»è¾‘æ¨ç†å’Œæƒ³è±¡èƒ½åŠ›ç­‰ï¼Œæœªæ¥ï¼Œæˆ‘ä»¬ä¹Ÿä¼šä¸æ–­ä¸°å¯Œå¤§æ¨¡å‹çš„å¤–å»¶èƒ½åŠ›ï¼Œä¾‹å¦‚çŸ¥è¯†åº“æ£€ç´¢ã€è®¡ç®—å·¥å…·ã€WolframAlphaã€æ“ä½œè½¯ä»¶ç­‰ã€‚
æˆ‘ä»¬é¦–å…ˆé›†æˆäº†LangChainæ¡†æ¶ï¼Œå¯ä»¥æ›´æ–¹ä¾¿åœ°åŸºäºLlama2å¼€å‘æ–‡æ¡£æ£€ç´¢ã€é—®ç­”æœºå™¨äººå’Œæ™ºèƒ½ä½“åº”ç”¨ç­‰ï¼Œå…³äºLangChainçš„æ›´å¤šä»‹ç»å‚è§[LangChain](https://github.com/langchain-ai/langchain)ã€‚

### LangChain
é’ˆå¯¹LangChainæ¡†æ¶å°è£…çš„Llama2 LLMç±»è§[examples/llama2_for_langchain.py](https://github.com/LlamaFamily/Llama-Chinese/blob/main/examples/llama2_for_langchain.py)ï¼Œç®€å•çš„è°ƒç”¨ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
from llama2_for_langchain import Llama2

# è¿™é‡Œä»¥è°ƒç”¨FlagAlpha/Atom-7B-Chatä¸ºä¾‹
llm = Llama2(model_name_or_path='FlagAlpha/Atom-7B-Chat')

while True:
    human_input = input("Human: ")
    response = llm(human_input)
    print(f"Llama2: {response}")
```

## ğŸ¥‡ æ¨¡å‹è¯„æµ‹

### Llama2å’ŒLlama3å¯¹æ¯”è¯„æµ‹
åŸºç¡€æ¨¡å‹å¯¹æ¯”
<p align="center" width="100%">
<img src="./assets/base_eval.png" style="width: 100%; display: block; margin: auto;">
</p>
å¾®è°ƒæ¨¡å‹å¯¹æ¯”
<p align="center" width="100%">
<img src="./assets/tuned_eval.png" style="width: 100%; display: block; margin: auto;">
</p>

### Llama3æ¨¡å‹è¯„æµ‹
<p align="center" width="100%">
<img src="./assets/llama3_eval.png" style="width: 100%; display: block; margin: auto;">
</p>

### Llama2æ¨¡å‹è¯„æµ‹
<p align="center" width="100%">
<img src="./assets/llama_eval.jpeg" style="width: 100%; display: block; margin: auto;">
</p>

ä¸ºäº†èƒ½å¤Ÿæ›´åŠ æ¸…æ™°åœ°äº†è§£Llama2æ¨¡å‹çš„ä¸­æ–‡é—®ç­”èƒ½åŠ›ï¼Œæˆ‘ä»¬ç­›é€‰äº†ä¸€äº›å…·æœ‰ä»£è¡¨æ€§çš„ä¸­æ–‡é—®é¢˜ï¼Œå¯¹Llama2æ¨¡å‹è¿›è¡Œæé—®ã€‚æˆ‘ä»¬æµ‹è¯•çš„æ¨¡å‹åŒ…å«Metaå…¬å¼€çš„Llama2-7B-Chatå’ŒLlama2-13B-Chatä¸¤ä¸ªç‰ˆæœ¬ï¼Œæ²¡æœ‰åšä»»ä½•å¾®è°ƒå’Œè®­ç»ƒã€‚æµ‹è¯•é—®é¢˜ç­›é€‰è‡ª[AtomBulb](https://github.com/AtomEcho/AtomBulb)ï¼Œå…±95ä¸ªæµ‹è¯•é—®é¢˜ï¼ŒåŒ…å«ï¼šé€šç”¨çŸ¥è¯†ã€è¯­è¨€ç†è§£ã€åˆ›ä½œèƒ½åŠ›ã€é€»è¾‘æ¨ç†ã€ä»£ç ç¼–ç¨‹ã€å·¥ä½œæŠ€èƒ½ã€ä½¿ç”¨å·¥å…·ã€äººæ ¼ç‰¹å¾å…«ä¸ªå¤§çš„ç±»åˆ«ã€‚

æµ‹è¯•ä¸­ä½¿ç”¨çš„Promptå¦‚ä¸‹ï¼Œä¾‹å¦‚å¯¹äºé—®é¢˜â€œåˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•â€ï¼š
```
[INST] 
<<SYS>>
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.

The answer always been translate into Chinese language.
<</SYS>>

åˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•
[/INST]
```
Llama2-7B-Chatçš„æµ‹è¯•ç»“æœè§[meta_eval_7B.md](assets/meta_eval_7B.md)ï¼ŒLlama2-13B-Chatçš„æµ‹è¯•ç»“æœè§[meta_eval_13B.md](assets/meta_eval_13B.md)ã€‚

é€šè¿‡æµ‹è¯•æˆ‘ä»¬å‘ç°ï¼ŒMetaåŸå§‹çš„Llama2 Chatæ¨¡å‹å¯¹äºä¸­æ–‡é—®ç­”çš„å¯¹é½æ•ˆæœä¸€èˆ¬ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹éƒ½ä¸èƒ½ç»™å‡ºä¸­æ–‡å›ç­”ï¼Œæˆ–è€…æ˜¯ä¸­è‹±æ–‡æ··æ‚çš„å½¢å¼ã€‚å› æ­¤ï¼ŒåŸºäºä¸­æ–‡æ•°æ®å¯¹Llama2æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œå¾®è°ƒååˆ†å¿…è¦ã€‚


## ğŸ“– å­¦ä¹ ä¸­å¿ƒ

### å®˜æ–¹æ–‡æ¡£
Meta Llamaå…¨ç³»åˆ—æ¨¡å‹å®˜æ–¹æ–‡æ¡£ï¼šhttps://llama.meta.com/docs/get-started

### Llama3
[Llama3å…¨å¥—å­¦ä¹ èµ„æ–™](https://chinesellama.feishu.cn/wiki/XBKPwbhWriWCfrkmJhfcrS9Rnqc?fromScene=spaceOverview)

Llama3å®˜æ–¹é“¾æ¥ï¼šhttps://llama.meta.com/llama3

### Llama2

#### Metaå®˜æ–¹å¯¹äº[Llama2](https://ai.meta.com/llama)çš„ä»‹ç»
è‡ªä»Metaå…¬å¸å‘å¸ƒç¬¬ä¸€ä»£LLaMAæ¨¡å‹ä»¥æ¥ï¼Œç¾Šé©¼æ¨¡å‹å®¶æ—ç¹è£å‘å±•ã€‚è¿‘æœŸMetaå‘å¸ƒäº†Llama2ç‰ˆæœ¬ï¼Œå¼€æºå¯å•†ç”¨ï¼Œåœ¨æ¨¡å‹å’Œæ•ˆæœä¸Šæœ‰äº†é‡å¤§æ›´æ–°ã€‚Llama2æ€»å…±å…¬å¸ƒäº†7Bã€13Bå’Œ70Bä¸‰ç§å‚æ•°å¤§å°çš„æ¨¡å‹ã€‚ç›¸æ¯”äºLLaMAï¼ŒLlama2çš„è®­ç»ƒæ•°æ®è¾¾åˆ°äº†2ä¸‡äº¿tokenï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä¹Ÿç”±ä¹‹å‰çš„2048å‡çº§åˆ°4096ï¼Œå¯ä»¥ç†è§£å’Œç”Ÿæˆæ›´é•¿çš„æ–‡æœ¬ã€‚Llama2 Chatæ¨¡å‹åŸºäº100ä¸‡äººç±»æ ‡è®°æ•°æ®å¾®è°ƒå¾—åˆ°ï¼Œåœ¨è‹±æ–‡å¯¹è¯ä¸Šè¾¾åˆ°äº†æ¥è¿‘ChatGPTçš„æ•ˆæœã€‚

### Llamaç›¸å…³è®ºæ–‡
* [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
* [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)
* [Code Llama: Open Foundation Models for Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/)


## ğŸ“Œ å…¶å®ƒ

### ğŸ‰ è‡´è°¢

æ„Ÿè°¢åŸå­å›å£°[AtomEcho](https://github.com/AtomEcho)å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼

æ„Ÿè°¢èŠ¯æ ¼[Coremesh](https://coremesh.net)å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼

æ„Ÿè°¢ [ç¦å·è¿å¤©æ•™è‚²ç§‘æŠ€æœ‰é™å…¬å¸](www.3class.cc) å¯¹Llamaä¸­æ–‡ç¤¾åŒºçš„è´¡çŒ®ï¼

æ„Ÿè°¢ @Z Potentialsç¤¾åŒºå¯¹Llamaä¸­æ–‡ç¤¾åŒºçš„æ”¯æŒï¼

### ğŸ¤” é—®é¢˜åé¦ˆ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·åœ¨GitHub Issueä¸­æäº¤ï¼Œåœ¨æäº¤é—®é¢˜ä¹‹å‰ï¼Œè¯·å…ˆæŸ¥é˜…ä»¥å¾€çš„issueæ˜¯å¦èƒ½è§£å†³ä½ çš„é—®é¢˜ã€‚

ç¤¼è²Œåœ°æå‡ºé—®é¢˜ï¼Œæ„å»ºå’Œè°çš„è®¨è®ºç¤¾åŒºã€‚

åŠ å…¥[é£ä¹¦çŸ¥è¯†åº“](https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink)ï¼Œä¸€èµ·å…±å»ºç¤¾åŒºæ–‡æ¡£ã€‚

åŠ å…¥å¾®ä¿¡ç¾¤è®¨è®ºğŸ˜ğŸ˜

<p align="center" width="100%">
<img src="./assets/wechat.jpeg" alt="Wechat" style="width: 100%; display: block; margin: auto;">
</p>

<p align="center" width="100%">
<img src="https://api.star-history.com/svg?repos=LlamaFamily/Llama-Chinese&type=Date" alt="Star" style="width: 100%; display: block; margin: auto;">
</p>
